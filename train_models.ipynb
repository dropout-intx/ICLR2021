{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBRegressor as xgb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(activation, dropout_rate=0.0, n_hidden=128):\n",
    "    print(\"Building model with {} activation and {:.3f} dropout\".format(activation, dropout_rate))\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(25,)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_hidden, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(n_hidden, activation=activation),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1, activation=tf.identity)\n",
    "    ])\n",
    "    sgd = tf.keras.optimizers.Adam(lr=1e-3)#, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    if activation == 'sigmoid':\n",
    "        model.compile(\n",
    "                      loss='MSE',\n",
    "                      metrics=['mse'],\n",
    "                     optimizer=sgd)\n",
    "    else:\n",
    "        model.compile(\n",
    "              loss='MSE',\n",
    "              metrics=['mse'],\n",
    "                     optimizer=sgd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with relu activation and 0.000 dropout\n",
      "0.0 0 0\n",
      "0.03418691 0.0032073674 0.002490637 4.3504786 4.583871\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 421us/sample - loss: 4.1836 - mse: 4.1836\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.9783 - mse: 3.9783\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.8725 - mse: 3.8725\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 101us/sample - loss: 3.7952 - mse: 3.7952\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 87us/sample - loss: 3.7183 - mse: 3.7183\n",
      "0.0 0 5\n",
      "0.10101339 0.0072883675 0.005400865 3.6596675 4.2597075\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 254us/sample - loss: 3.6532 - mse: 3.6532\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 96us/sample - loss: 3.5982 - mse: 3.5982\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 81us/sample - loss: 3.5494 - mse: 3.5494\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.5092 - mse: 3.5092\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.4645 - mse: 3.4645\n",
      "0.0 0 10\n",
      "0.2309653 0.009959322 0.008153038 3.410972 4.1920214\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.4233 - mse: 3.4233\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 3.3805 - mse: 3.3805\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.3406 - mse: 3.3406\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.3148 - mse: 3.3148\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.2657 - mse: 3.2657\n",
      "0.0 0 15\n",
      "0.33992532 0.0155248325 0.013401612 3.2075756 4.2107677\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 74us/sample - loss: 3.2284 - mse: 3.2284\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 82us/sample - loss: 3.1885 - mse: 3.1885\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 93us/sample - loss: 3.1599 - mse: 3.1599\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.1208 - mse: 3.1208\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 3.0692 - mse: 3.0692\n",
      "0.0 0 20\n",
      "0.38664654 0.02284144 0.021043174 3.0069494 4.204542\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.0289 - mse: 3.0289\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 2.9888 - mse: 2.9888\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 2.9446 - mse: 2.9446\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 2.9248 - mse: 2.9248\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 2.9082 - mse: 2.9082\n",
      "0.0 0 25\n",
      "0.39750144 0.031131353 0.03049223 2.8295949 4.2770405\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 76us/sample - loss: 2.8584 - mse: 2.8584\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 69us/sample - loss: 2.7835 - mse: 2.7835\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 2.7673 - mse: 2.7673\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 2.7054 - mse: 2.7054\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 2.6648 - mse: 2.6648\n",
      "0.0 0 30\n",
      "0.44917333 0.04635788 0.051863074 2.5971458 4.349856\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 2.6285 - mse: 2.6285\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 2.5791 - mse: 2.5791\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 2.5398 - mse: 2.5398\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 2.4912 - mse: 2.4912\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 2.4562 - mse: 2.4562\n",
      "0.0 0 35\n",
      "0.41080195 0.06035923 0.062770024 2.3746467 4.4288783\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 2.4264 - mse: 2.4264\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 2.3849 - mse: 2.3849\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 2.3487 - mse: 2.3487\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 2.2926 - mse: 2.2926\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 100us/sample - loss: 2.2639 - mse: 2.2639\n",
      "0.0 0 40\n",
      "0.4307634 0.078334354 0.080639325 2.189688 4.5784044\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 2.2286 - mse: 2.2286\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 2.1874 - mse: 2.1874\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 2.1592 - mse: 2.1592\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 2.1243 - mse: 2.1243\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 2.0776 - mse: 2.0776\n",
      "0.0 0 45\n",
      "0.4263874 0.09454475 0.10150922 2.0338576 4.740194\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 2.0649 - mse: 2.0649\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 2.0180 - mse: 2.0180\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 2.0114 - mse: 2.0114\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 1.9612 - mse: 1.9612\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 1.9544 - mse: 1.9544\n",
      "0.0 0 50\n",
      "0.4291496 0.10940304 0.10674058 1.8555992 4.808432\n",
      "0.0 0 75\n",
      "0.44530684 0.19062829 0.17243533 1.2315189 5.4172425\n",
      "0.0 0 100\n",
      "0.48511973 0.24084897 0.23379263 0.8796461 6.030703\n",
      "0.0 0 125\n",
      "0.55637074 0.29939628 0.26865724 0.6460248 6.5530233\n",
      "0.0 0 150\n",
      "0.5542372 0.31204906 0.33461928 0.44847232 6.9158254\n",
      "0.0 0 175\n",
      "0.5783922 0.35087654 0.35325867 0.32435113 7.421666\n",
      "0.0 0 200\n",
      "0.5628414 0.39001265 0.39995894 0.2439714 7.7807865\n",
      "0.0 0 225\n",
      "0.6156796 0.42026192 0.45481485 0.16728453 8.186831\n",
      "0.0 0 250\n",
      "0.62862015 0.4441744 0.42948037 0.12910298 8.576298\n",
      "0.0 0 275\n",
      "0.71281797 0.46635556 0.4432432 0.09466019 8.9467535\n",
      "0.0 0 300\n",
      "0.6538125 0.46906045 0.46285918 0.07208576 9.179325\n",
      "0.0 0 325\n",
      "0.718409 0.48865128 0.49624512 0.058928642 9.587812\n",
      "0.0 0 350\n",
      "0.6973457 0.5081262 0.5008877 0.042470917 9.775238\n",
      "0.0 0 375\n",
      "0.7076528 0.51984286 0.5521374 0.033598475 10.045071\n",
      "0.0 0 400\n",
      "0.6939934 0.52797854 0.5394788 0.024630105 10.176483\n",
      "0.0 0 425\n",
      "0.649633 0.53813726 0.55403984 0.019010326 10.232906\n",
      "0.0 0 450\n",
      "0.69534385 0.5349748 0.5755653 0.017314795 10.362626\n",
      "0.0 0 475\n",
      "0.7074766 0.5599958 0.59342176 0.01798954 10.393404\n",
      "Building model with relu activation and 0.000 dropout\n",
      "0.0 1 0\n",
      "0.06976998 0.0057166363 0.0040756064 4.770678 4.886996\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 275us/sample - loss: 4.3475 - mse: 4.3475\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0551 - mse: 4.0551\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9075 - mse: 3.9075\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8125 - mse: 3.8125\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7210 - mse: 3.7210\n",
      "0.0 1 5\n",
      "0.07906076 0.007476483 0.0055290284 3.6385872 4.267308\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.6292 - mse: 3.6292\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.5700 - mse: 3.5700\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.5158 - mse: 3.5158\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.4660 - mse: 3.4660\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.4269 - mse: 3.4269\n",
      "0.0 1 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21843472 0.012178106 0.010635132 3.3715413 4.203711\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.3867 - mse: 3.3867\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.3465 - mse: 3.3465\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.3247 - mse: 3.3247\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - ETA: 0s - loss: 3.3047 - mse: 3.304 - 0s 41us/sample - loss: 3.2774 - mse: 3.2774\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.2391 - mse: 3.2391\n",
      "0.0 1 15\n",
      "0.2920759 0.01828909 0.015767355 3.1751611 4.2471457\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.1982 - mse: 3.1982\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.1661 - mse: 3.1661\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.1258 - mse: 3.1258\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.0804 - mse: 3.0804\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.0421 - mse: 3.0421\n",
      "0.0 1 20\n",
      "0.33946934 0.028885962 0.025761837 2.9726045 4.319376\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.0029 - mse: 3.0029\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 214us/sample - loss: 2.9663 - mse: 2.9663\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 85us/sample - loss: 2.9177 - mse: 2.9177\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 2.9028 - mse: 2.9028\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 2.8450 - mse: 2.8450\n",
      "0.0 1 25\n",
      "0.403683 0.044444177 0.038010772 2.7671223 4.4380846\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 2.8025 - mse: 2.8025\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 2.7651 - mse: 2.7651\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 2.7256 - mse: 2.7256\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 71us/sample - loss: 2.6947 - mse: 2.6947\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 2.6467 - mse: 2.6467\n",
      "0.0 1 30\n",
      "0.37854558 0.059541047 0.052740693 2.559984 4.545582\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 2.5891 - mse: 2.5891\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 2.5572 - mse: 2.5572\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 2.5190 - mse: 2.5190\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 69us/sample - loss: 2.4700 - mse: 2.4700\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 2.4290 - mse: 2.4290\n",
      "0.0 1 35\n",
      "0.41767696 0.0808916 0.07053287 2.3412845 4.6663966\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 2.3917 - mse: 2.3917\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 2.3515 - mse: 2.3515\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 2.3065 - mse: 2.3065\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 2.2702 - mse: 2.2702\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 2.2209 - mse: 2.2209\n",
      "0.0 1 40\n",
      "0.3930721 0.10304046 0.08432732 2.1350448 4.7776766\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 71us/sample - loss: 2.1991 - mse: 2.1991\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 2.1378 - mse: 2.1378\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 2.1231 - mse: 2.1231\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 2.0875 - mse: 2.0875\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 2.0404 - mse: 2.0404\n",
      "0.0 1 45\n",
      "0.39709783 0.120091006 0.10775657 1.9615443 4.909516\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 2.0116 - mse: 2.0116\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 1.9711 - mse: 1.9711\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 1.9351 - mse: 1.9351\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 1.9072 - mse: 1.9072\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 1.8726 - mse: 1.8726\n",
      "0.0 1 50\n",
      "0.41082022 0.14720613 0.1292155 1.7948073 5.0558963\n",
      "0.0 1 75\n",
      "0.4494511 0.21654987 0.20683716 1.2335423 5.6392407\n",
      "0.0 1 100\n",
      "0.5146394 0.25828925 0.25264478 0.89785826 6.1882\n",
      "0.0 1 125\n",
      "0.46434072 0.31954542 0.28689864 0.6624235 6.5186453\n",
      "0.0 1 150\n",
      "0.50148773 0.33332047 0.33763614 0.5048533 6.940376\n",
      "0.0 1 175\n",
      "0.50628376 0.3588983 0.38645533 0.3753162 7.2615952\n",
      "0.0 1 200\n",
      "0.52314407 0.38009268 0.4212212 0.26078913 7.498658\n",
      "0.0 1 225\n",
      "0.51692253 0.4213657 0.43229043 0.20287071 7.7811685\n",
      "0.0 1 250\n",
      "0.5451803 0.45368317 0.46363297 0.13654104 7.9697876\n",
      "0.0 1 275\n",
      "0.5520754 0.47216094 0.506015 0.09447713 8.240937\n",
      "0.0 1 300\n",
      "0.5636239 0.50996494 0.538829 0.0752724 8.539277\n",
      "0.0 1 325\n",
      "0.57032263 0.52851003 0.54796374 0.054222543 8.7507925\n",
      "0.0 1 350\n",
      "0.5837138 0.55440533 0.5336978 0.042848844 8.978173\n",
      "0.0 1 375\n",
      "0.55400723 0.5579643 0.5618762 0.032962777 9.199776\n",
      "0.0 1 400\n",
      "0.6055538 0.57490355 0.60904205 0.02855234 9.307996\n",
      "0.0 1 425\n",
      "0.5952985 0.56971955 0.61113495 0.01883133 9.459656\n",
      "0.0 1 450\n",
      "0.59664685 0.58746624 0.61889833 0.015666286 9.568944\n",
      "0.0 1 475\n",
      "0.5973617 0.5955463 0.6152545 0.013203344 9.677327\n",
      "Building model with relu activation and 0.000 dropout\n",
      "0.0 2 0\n",
      "0.03729044 0.0039026216 0.0026313977 4.436993 4.6288247\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 316us/sample - loss: 4.1727 - mse: 4.1727\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 71us/sample - loss: 3.9416 - mse: 3.9416\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 3.8261 - mse: 3.8261\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 71us/sample - loss: 3.7388 - mse: 3.7388\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 3.6722 - mse: 3.6722\n",
      "0.0 2 5\n",
      "0.12849781 0.008500349 0.0050969557 3.6069903 4.148648\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.6032 - mse: 3.6032\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.5468 - mse: 3.5468\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 100us/sample - loss: 3.4935 - mse: 3.4935\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 100us/sample - loss: 3.4452 - mse: 3.4452\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 81us/sample - loss: 3.3959 - mse: 3.3959\n",
      "0.0 2 10\n",
      "0.23729834 0.0132079525 0.009010044 3.3398573 4.096705\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 104us/sample - loss: 3.3548 - mse: 3.3548\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 74us/sample - loss: 3.3279 - mse: 3.3279\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 88us/sample - loss: 3.2635 - mse: 3.2635\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.2280 - mse: 3.2280\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 81us/sample - loss: 3.1877 - mse: 3.1877\n",
      "0.0 2 15\n",
      "0.26075712 0.019500209 0.016251324 3.1334128 4.1178703\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 3.1553 - mse: 3.1553\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.0983 - mse: 3.0983\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.0530 - mse: 3.0530\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.0116 - mse: 3.0116\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 105us/sample - loss: 2.9827 - mse: 2.9827\n",
      "0.0 2 20\n",
      "0.31700054 0.033422448 0.026017776 2.912898 4.201748\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 67us/sample - loss: 2.9327 - mse: 2.9327\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 2.8963 - mse: 2.8963\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 2.8536 - mse: 2.8536\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 2.8107 - mse: 2.8107\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 2.7707 - mse: 2.7707\n",
      "0.0 2 25\n",
      "0.32555112 0.047699414 0.042585287 2.6945086 4.2887645\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 2.7240 - mse: 2.7240\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 2.6840 - mse: 2.6840\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 2.6588 - mse: 2.6588\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 2.6100 - mse: 2.6100\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 2.5562 - mse: 2.5562\n",
      "0.0 2 30\n",
      "0.39776918 0.06873499 0.0647149 2.4962013 4.4353123\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 2.5172 - mse: 2.5172\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 2.4699 - mse: 2.4699\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 2.4306 - mse: 2.4306\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 2.4005 - mse: 2.4005\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 2.3703 - mse: 2.3703\n",
      "0.0 2 35\n",
      "0.3749028 0.08587175 0.079451025 2.2787917 4.5453463\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 2.3288 - mse: 2.3288\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 2.2780 - mse: 2.2780\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 2.2382 - mse: 2.2382\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 2.2107 - mse: 2.2107\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 2.1785 - mse: 2.1785\n",
      "0.0 2 40\n",
      "0.3825145 0.11062366 0.09762231 2.0909033 4.6668744\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 2.1277 - mse: 2.1277\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 2.1056 - mse: 2.1056\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 2.0643 - mse: 2.0643\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 2.0213 - mse: 2.0213\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 2.0052 - mse: 2.0052\n",
      "0.0 2 45\n",
      "0.38005868 0.1340818 0.11656608 1.9125178 4.8141\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 1.9685 - mse: 1.9685\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 1.9350 - mse: 1.9351\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 1.9157 - mse: 1.9157\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 1.8845 - mse: 1.8845\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 1.8645 - mse: 1.8645\n",
      "0.0 2 50\n",
      "0.37785384 0.15208857 0.14636812 1.7948045 4.9569745\n",
      "0.0 2 75\n",
      "0.4373399 0.2270307 0.21608882 1.2228122 5.584746\n",
      "0.0 2 100\n",
      "0.45974848 0.29498687 0.29163975 0.86049044 6.0585623\n",
      "0.0 2 125\n",
      "0.48751968 0.34015462 0.33148274 0.6592668 6.6549416\n",
      "0.0 2 150\n",
      "0.5814607 0.3711439 0.3782506 0.49155676 7.1333227\n",
      "0.0 2 175\n",
      "0.62144846 0.42338842 0.41384062 0.37180197 7.612897\n",
      "0.0 2 200\n",
      "0.63423496 0.4528413 0.44228622 0.2738196 7.9962344\n",
      "0.0 2 225\n",
      "0.64459676 0.48814297 0.49272656 0.19847521 8.396562\n",
      "0.0 2 250\n",
      "0.7254316 0.5184549 0.54911023 0.13955748 8.845556\n",
      "0.0 2 275\n",
      "0.72339076 0.55231905 0.54711145 0.0966467 9.061931\n",
      "0.0 2 300\n",
      "0.78666514 0.56587297 0.54518074 0.07605245 9.36249\n",
      "0.0 2 325\n",
      "0.8008906 0.5790134 0.5972127 0.047779102 9.549843\n",
      "0.0 2 350\n",
      "0.7993462 0.6053453 0.6125254 0.030900845 9.762737\n",
      "0.0 2 375\n",
      "0.798692 0.61697936 0.62916106 0.023862936 9.853045\n",
      "0.0 2 400\n",
      "0.7848555 0.6385212 0.65527534 0.021217639 9.977583\n",
      "0.0 2 425\n",
      "0.80129415 0.64111984 0.6670794 0.016221523 10.117606\n",
      "0.0 2 450\n",
      "0.7818705 0.64403886 0.66781175 0.017014423 10.143386\n",
      "0.0 2 475\n",
      "0.79123116 0.654741 0.6632064 0.015885282 10.193102\n",
      "Building model with relu activation and 0.125 dropout\n",
      "0.125 0 0\n",
      "0.054013435 0.007112091 0.005602804 4.4077897 4.606427\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 1s 491us/sample - loss: 4.1824 - mse: 4.1823\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 4.0108 - mse: 4.0108\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.9213 - mse: 3.9213\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.8818 - mse: 3.8818\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 67us/sample - loss: 3.9442 - mse: 3.9442\n",
      "0.125 0 5\n",
      "0.08464302 0.0071710297 0.0051081916 3.723204 4.176779\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 78us/sample - loss: 3.8136 - mse: 3.8136\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.8507 - mse: 3.8507\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 82us/sample - loss: 3.7108 - mse: 3.7108\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.7317 - mse: 3.7317\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 3.7251 - mse: 3.7251\n",
      "0.125 0 10\n",
      "0.14043838 0.0072519286 0.0062126145 3.564841 4.0864\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.6015 - mse: 3.6015\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 3.7145 - mse: 3.7145\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 3.7126 - mse: 3.7126\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 3.6024 - mse: 3.6024\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 3.6165 - mse: 3.6165\n",
      "0.125 0 15\n",
      "0.17486301 0.0084847035 0.007363845 3.462013 4.0977845\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 3.7267 - mse: 3.7267\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.6245 - mse: 3.6245\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 3.6064 - mse: 3.6064\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 3.6221 - mse: 3.6221\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 3.5629 - mse: 3.5629\n",
      "0.125 0 20\n",
      "0.19714344 0.009804707 0.0077983644 3.376998 4.071422\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 85us/sample - loss: 3.6186 - mse: 3.6186\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 67us/sample - loss: 3.6229 - mse: 3.6229\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 3.5794 - mse: 3.5794\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 81us/sample - loss: 3.5158 - mse: 3.5158\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 3.6182 - mse: 3.6182\n",
      "0.125 0 25\n",
      "0.20074007 0.010655865 0.008796962 3.303998 4.0781374\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.4903 - mse: 3.4903\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 3.4826 - mse: 3.4826\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 76us/sample - loss: 3.5330 - mse: 3.5330\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.5059 - mse: 3.5059\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.5330 - mse: 3.5330\n",
      "0.125 0 30\n",
      "0.21286006 0.0130352555 0.00946035 3.2317405 4.0897083\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 3.5268 - mse: 3.5268\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.4147 - mse: 3.4147\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.5157 - mse: 3.5157\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.4392 - mse: 3.4392\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.4257 - mse: 3.4257\n",
      "0.125 0 35\n",
      "0.1888867 0.013181158 0.010411399 3.1678638 4.0894923\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 76us/sample - loss: 3.3943 - mse: 3.3943\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 3.4286 - mse: 3.4286\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.4120 - mse: 3.4121\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.4023 - mse: 3.4023\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.3735 - mse: 3.3735\n",
      "0.125 0 40\n",
      "0.22727673 0.017676752 0.013657323 3.0724175 4.1195254\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 205us/sample - loss: 3.3775 - mse: 3.3775\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 89us/sample - loss: 3.3912 - mse: 3.3912\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 120us/sample - loss: 3.3287 - mse: 3.3287\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 135us/sample - loss: 3.3357 - mse: 3.3357\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 277us/sample - loss: 3.3895 - mse: 3.3895\n",
      "0.125 0 45\n",
      "0.21118574 0.019460913 0.015253647 3.0132644 4.1128182\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.2732 - mse: 3.2732\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.3221 - mse: 3.3221\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.2625 - mse: 3.2625\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 71us/sample - loss: 3.2723 - mse: 3.2723\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 77us/sample - loss: 3.3206 - mse: 3.3206\n",
      "0.125 0 50\n",
      "0.2101692 0.02063661 0.015495401 2.9590554 4.1461987\n",
      "0.125 0 75\n",
      "0.24847612 0.034943458 0.028859414 2.5779884 4.2139373\n",
      "0.125 0 100\n",
      "0.22376747 0.040013682 0.034092713 2.3449705 4.301981\n",
      "0.125 0 125\n",
      "0.20686233 0.047650136 0.04106957 2.1475608 4.397322\n",
      "0.125 0 150\n",
      "0.20080352 0.05342265 0.04675859 1.995589 4.4175754\n",
      "0.125 0 175\n",
      "0.2019469 0.054024816 0.05569043 1.8536648 4.510005\n",
      "0.125 0 200\n",
      "0.18271568 0.056567714 0.05374251 1.7642463 4.5483484\n",
      "0.125 0 225\n",
      "0.18228322 0.05404917 0.061513007 1.6810447 4.5960035\n",
      "0.125 0 250\n",
      "0.2004513 0.05476109 0.06042564 1.5808407 4.608477\n",
      "0.125 0 275\n",
      "0.18892023 0.055719014 0.06328298 1.5482912 4.5751753\n",
      "0.125 0 300\n",
      "0.21193276 0.05792546 0.06160347 1.4843937 4.505425\n",
      "0.125 0 325\n",
      "0.21236992 0.062018517 0.064288594 1.4137243 4.5210857\n",
      "0.125 0 350\n",
      "0.19492303 0.056983136 0.060869176 1.4065032 4.4757032\n",
      "0.125 0 375\n",
      "0.18541995 0.058265064 0.061459925 1.3940551 4.516848\n",
      "0.125 0 400\n",
      "0.19713503 0.05969867 0.06511849 1.3225386 4.4817915\n",
      "0.125 0 425\n",
      "0.19799392 0.05676023 0.058826245 1.3010284 4.50836\n",
      "0.125 0 450\n",
      "0.1759883 0.058874995 0.06287134 1.281275 4.493116\n",
      "0.125 0 475\n",
      "0.1859126 0.058081187 0.052409876 1.2768223 4.482627\n",
      "Building model with relu activation and 0.125 dropout\n",
      "0.125 1 0\n",
      "0.054076564 0.0050673867 0.0036604488 4.9317727 5.0747\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 1s 557us/sample - loss: 4.4573 - mse: 4.4573\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 4.0918 - mse: 4.0918\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.0232 - mse: 4.0232\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.9703 - mse: 3.9703\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 83us/sample - loss: 3.8645 - mse: 3.8645\n",
      "0.125 1 5\n",
      "0.06411286 0.004685906 0.0040334472 3.7700438 4.202293\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.8835 - mse: 3.8835\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.7940 - mse: 3.7940\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.8014 - mse: 3.8014\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.7988 - mse: 3.7988\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.7021 - mse: 3.7021\n",
      "0.125 1 10\n",
      "0.13197568 0.0070407614 0.0050522154 3.5655947 4.10751\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.7017 - mse: 3.7017\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.6459 - mse: 3.6459\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.6413 - mse: 3.6413\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.6220 - mse: 3.6220\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.6444 - mse: 3.6444\n",
      "0.125 1 15\n",
      "0.16962288 0.008705016 0.0060971426 3.4440932 4.098379\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 3.6413 - mse: 3.6413\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 3.6420 - mse: 3.6420\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.5836 - mse: 3.5836\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.6076 - mse: 3.6076\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 63us/sample - loss: 3.5788 - mse: 3.5788\n",
      "0.125 1 20\n",
      "0.1709473 0.009882174 0.0075713936 3.360343 4.0865116\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.5974 - mse: 3.5974\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 78us/sample - loss: 3.4903 - mse: 3.4903\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.4737 - mse: 3.4737\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.4088 - mse: 3.4088\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.5050 - mse: 3.5050\n",
      "0.125 1 25\n",
      "0.20969974 0.013228601 0.009939217 3.2599664 4.1087327\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.5030 - mse: 3.5030\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 3.4197 - mse: 3.4197\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 77us/sample - loss: 3.4686 - mse: 3.4686\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.4283 - mse: 3.4283\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.4535 - mse: 3.4535\n",
      "0.125 1 30\n",
      "0.21886101 0.014202588 0.011827729 3.1818025 4.0938296\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.4637 - mse: 3.4637\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.4281 - mse: 3.4281\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.4299 - mse: 3.4299\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.4285 - mse: 3.4285\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.4247 - mse: 3.42470s - loss: 3.3210 - mse: 3.321\n",
      "0.125 1 35\n",
      "0.22297764 0.01670659 0.014766863 3.0975728 4.112469\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.3302 - mse: 3.3302\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.4573 - mse: 3.4573\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 3.3571 - mse: 3.3571\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.3713 - mse: 3.3713\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.4298 - mse: 3.4298\n",
      "0.125 1 40\n",
      "0.22579561 0.019286 0.017330186 3.0272965 4.125795\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.3683 - mse: 3.3683\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.3123 - mse: 3.3123\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.2718 - mse: 3.2718\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.3740 - mse: 3.3740\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.3176 - mse: 3.3176\n",
      "0.125 1 45\n",
      "0.20687456 0.020325487 0.018560547 2.9661188 4.136082\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.2840 - mse: 3.2840\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.2396 - mse: 3.2396\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.2234 - mse: 3.2234\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.2474 - mse: 3.2474\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.2353 - mse: 3.2353\n",
      "0.125 1 50\n",
      "0.21941549 0.024088265 0.021996122 2.8930404 4.1791945\n",
      "0.125 1 75\n",
      "0.2265227 0.0360896 0.029409003 2.5659578 4.232172\n",
      "0.125 1 100\n",
      "0.21023135 0.04368426 0.039451808 2.3587625 4.3013134\n",
      "0.125 1 125\n",
      "0.2091896 0.048882514 0.041525275 2.1863747 4.3262806\n",
      "0.125 1 150\n",
      "0.23199758 0.051322557 0.043626197 2.0460687 4.32337\n",
      "0.125 1 175\n",
      "0.21303672 0.052009325 0.04820737 1.941138 4.3988857\n",
      "0.125 1 200\n",
      "0.18516617 0.051183008 0.048511367 1.8592318 4.3986073\n",
      "0.125 1 225\n",
      "0.19433719 0.05564837 0.05102306 1.726842 4.4415116\n",
      "0.125 1 250\n",
      "0.17074443 0.057149645 0.05219693 1.6804713 4.400029\n",
      "0.125 1 275\n",
      "0.17349373 0.061187018 0.05223204 1.5917149 4.3801317\n",
      "0.125 1 300\n",
      "0.16993628 0.061010156 0.050927136 1.5315661 4.398267\n",
      "0.125 1 325\n",
      "0.16360481 0.060475416 0.052818384 1.4817265 4.3830533\n",
      "0.125 1 350\n",
      "0.15784119 0.060484547 0.053795327 1.453184 4.422487\n",
      "0.125 1 375\n",
      "0.1663535 0.061594408 0.05831937 1.4062675 4.4932165\n",
      "0.125 1 400\n",
      "0.1495396 0.060253974 0.05525891 1.3837163 4.4558544\n",
      "0.125 1 425\n",
      "0.15695933 0.063697696 0.056128368 1.3360106 4.476703\n",
      "0.125 1 450\n",
      "0.1672896 0.06322517 0.057097375 1.3175935 4.4450555\n",
      "0.125 1 475\n",
      "0.16217592 0.06081374 0.055468593 1.3104638 4.4537826\n",
      "Building model with relu activation and 0.125 dropout\n",
      "0.125 2 0\n",
      "0.029056061 0.003755187 0.0027443771 4.6632724 4.7846336\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 1s 750us/sample - loss: 4.3235 - mse: 4.3235\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0251 - mse: 4.0251\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.9282 - mse: 3.9282\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.9093 - mse: 3.9093\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.7999 - mse: 3.7999\n",
      "0.125 2 5\n",
      "0.0951302 0.006205336 0.0040735104 3.7225044 4.165486\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.7808 - mse: 3.7808\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.7982 - mse: 3.7982\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.8061 - mse: 3.8061\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.6889 - mse: 3.6889\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 3.6856 - mse: 3.6856\n",
      "0.125 2 10\n",
      "0.15442607 0.0070558656 0.0053890753 3.5606549 4.066402\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 3.7727 - mse: 3.7727\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.6541 - mse: 3.6541\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.6726 - mse: 3.6726\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.6182 - mse: 3.6182\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.6967 - mse: 3.6967\n",
      "0.125 2 15\n",
      "0.17659341 0.008258027 0.0065731695 3.4563472 4.040345\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.6312 - mse: 3.6312\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 3.6151 - mse: 3.6151\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.5880 - mse: 3.5880\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.6002 - mse: 3.6002\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.6897 - mse: 3.6897\n",
      "0.125 2 20\n",
      "0.183875 0.008703291 0.006992824 3.3771536 4.0230994\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.5592 - mse: 3.5592\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.5219 - mse: 3.5219\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.5544 - mse: 3.5544\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.5279 - mse: 3.5279\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.5459 - mse: 3.5459\n",
      "0.125 2 25\n",
      "0.21354239 0.010641321 0.009774863 3.3049479 4.0411024\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.5512 - mse: 3.5512\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.4988 - mse: 3.4988\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.4968 - mse: 3.4968\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.5086 - mse: 3.5086\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.4731 - mse: 3.4731\n",
      "0.125 2 30\n",
      "0.23883587 0.013515619 0.012291488 3.22251 4.0126595\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.4396 - mse: 3.4396\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.4802 - mse: 3.4802\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.4612 - mse: 3.4612\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.4224 - mse: 3.4224\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.3969 - mse: 3.3969\n",
      "0.125 2 35\n",
      "0.20122224 0.01419218 0.012742387 3.1663902 4.0403013\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.3874 - mse: 3.3874\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.3686 - mse: 3.3686\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.4244 - mse: 3.4244\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.3604 - mse: 3.3604\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.3616 - mse: 3.3616\n",
      "0.125 2 40\n",
      "0.21718799 0.01769596 0.01833235 3.083035 4.032451\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 3.4325 - mse: 3.4325\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 3.2901 - mse: 3.2901\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 3.2359 - mse: 3.2359\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.3354 - mse: 3.3354\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.4270 - mse: 3.4270\n",
      "0.125 2 45\n",
      "0.23204604 0.02030631 0.019794814 3.0143046 4.0830994\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 3.3948 - mse: 3.3948\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.3824 - mse: 3.3824\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.2185 - mse: 3.2185\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 3.3355 - mse: 3.3355\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.2274 - mse: 3.2274\n",
      "0.125 2 50\n",
      "0.235234 0.024116552 0.021323282 2.9508955 4.1231403\n",
      "0.125 2 75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23009007 0.033781156 0.0314988 2.6502213 4.158754\n",
      "0.125 2 100\n",
      "0.20635512 0.041453883 0.035569485 2.427912 4.184235\n",
      "0.125 2 125\n",
      "0.20002113 0.043845158 0.04191437 2.229736 4.237162\n",
      "0.125 2 150\n",
      "0.20712371 0.051955774 0.05073486 2.0475526 4.32006\n",
      "0.125 2 175\n",
      "0.21127354 0.055083532 0.051137976 1.9026302 4.37145\n",
      "0.125 2 200\n",
      "0.19654243 0.05782954 0.05168313 1.80881 4.3860145\n",
      "0.125 2 225\n",
      "0.17237878 0.05652826 0.055682957 1.7445693 4.407841\n",
      "0.125 2 250\n",
      "0.19351985 0.056568958 0.05884784 1.6731434 4.365589\n",
      "0.125 2 275\n",
      "0.18472476 0.05875873 0.066162705 1.5789185 4.4491167\n",
      "0.125 2 300\n",
      "0.16066693 0.059081018 0.056907643 1.5500829 4.473304\n",
      "0.125 2 325\n",
      "0.19060063 0.060224272 0.059816796 1.4775199 4.473453\n",
      "0.125 2 350\n",
      "0.19657136 0.06594061 0.060679786 1.4146485 4.470878\n",
      "0.125 2 375\n",
      "0.17213257 0.06287635 0.065763734 1.3772448 4.471309\n",
      "0.125 2 400\n",
      "0.18017 0.063772 0.06824822 1.3588325 4.4476023\n",
      "0.125 2 425\n",
      "0.17814453 0.06159881 0.0651617 1.3112602 4.446019\n",
      "0.125 2 450\n",
      "0.19105703 0.06382444 0.06430163 1.288131 4.5105386\n",
      "0.125 2 475\n",
      "0.1804886 0.06564087 0.06840824 1.2377295 4.586664\n",
      "Building model with relu activation and 0.250 dropout\n",
      "0.25 0 0\n",
      "0.06103556 0.004816974 0.002663942 4.747848 4.9169497\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 327us/sample - loss: 4.3662 - mse: 4.3662\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0910 - mse: 4.0910\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1149 - mse: 4.1149\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0682 - mse: 4.0682\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0213 - mse: 4.0213\n",
      "0.25 0 5\n",
      "0.04246198 0.003560913 0.002640625 3.8091593 4.190035\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9658 - mse: 3.9658\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9474 - mse: 3.9474\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.8750 - mse: 3.8750\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.9322 - mse: 3.9322\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.8625 - mse: 3.8625\n",
      "0.25 0 10\n",
      "0.057816297 0.0032017734 0.0024843407 3.744229 4.1559324\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8986 - mse: 3.8986\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8443 - mse: 3.8443\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8108 - mse: 3.8108\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8291 - mse: 3.8291\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.8693 - mse: 3.8693\n",
      "0.25 0 15\n",
      "0.077453315 0.0035593982 0.002606243 3.690455 4.1356335\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8051 - mse: 3.8051\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.8251 - mse: 3.8251\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.8246 - mse: 3.8246\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7478 - mse: 3.7478\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.7792 - mse: 3.7792\n",
      "0.25 0 20\n",
      "0.09300027 0.0032111767 0.0029025173 3.627318 4.10995\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8356 - mse: 3.8356\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8000 - mse: 3.8000\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7826 - mse: 3.7826\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8164 - mse: 3.8164\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8061 - mse: 3.8061\n",
      "0.25 0 25\n",
      "0.088586405 0.0034546298 0.002704989 3.6096206 4.11492\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.7327 - mse: 3.7327\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7036 - mse: 3.7036\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7674 - mse: 3.7674\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8444 - mse: 3.8444\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7520 - mse: 3.7520\n",
      "0.25 0 30\n",
      "0.101923816 0.0040470087 0.0029670768 3.5675902 4.1258264\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.7614 - mse: 3.7614\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.7702 - mse: 3.7702\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.7704 - mse: 3.7704\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.6966 - mse: 3.6966\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.6542 - mse: 3.6542\n",
      "0.25 0 35\n",
      "0.12164143 0.005078704 0.0033307397 3.5243173 4.1257124\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7074 - mse: 3.7074\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6161 - mse: 3.6161\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7654 - mse: 3.7654\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.7131 - mse: 3.7131\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7457 - mse: 3.7457\n",
      "0.25 0 40\n",
      "0.11392256 0.0050611543 0.0034764602 3.5139124 4.134195\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.6814 - mse: 3.6814\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.6913 - mse: 3.6913\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.6004 - mse: 3.6004\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.7093 - mse: 3.7093\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.7850 - mse: 3.7850\n",
      "0.25 0 45\n",
      "0.108629934 0.005147068 0.0034539371 3.505694 4.135085\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.6075 - mse: 3.6075\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7251 - mse: 3.7251\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.6338 - mse: 3.6338\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7315 - mse: 3.7315\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.6556 - mse: 3.6556\n",
      "0.25 0 50\n",
      "0.14064413 0.006484076 0.0040606973 3.436592 4.1223264\n",
      "0.25 0 75\n",
      "0.11802119 0.007913673 0.0062288498 3.3301754 4.12994\n",
      "0.25 0 100\n",
      "0.108161524 0.01110478 0.008559395 3.2052746 4.165663\n",
      "0.25 0 125\n",
      "0.1060739 0.012908706 0.010012636 3.100914 4.2153387\n",
      "0.25 0 150\n",
      "0.12085636 0.015845915 0.012992818 2.9948146 4.2072935\n",
      "0.25 0 175\n",
      "0.116294265 0.017776845 0.014565411 2.8933358 4.2139335\n",
      "0.25 0 200\n",
      "0.12347694 0.018457217 0.015452273 2.825307 4.205569\n",
      "0.25 0 225\n",
      "0.10325475 0.018021228 0.01631 2.7938762 4.1956897\n",
      "0.25 0 250\n",
      "0.09352483 0.018352183 0.01531976 2.7803512 4.19991\n",
      "0.25 0 275\n",
      "0.09582813 0.017482186 0.01659878 2.7413793 4.161758\n",
      "0.25 0 300\n",
      "0.10014679 0.019240407 0.017822275 2.6850429 4.1978774\n",
      "0.25 0 325\n",
      "0.08954766 0.018941369 0.01777157 2.6763473 4.181858\n",
      "0.25 0 350\n",
      "0.100192435 0.021043247 0.019225715 2.6144273 4.2405744\n",
      "0.25 0 375\n",
      "0.09128203 0.019409304 0.017937787 2.6153336 4.21622\n",
      "0.25 0 400\n",
      "0.086844444 0.019185955 0.017032348 2.609057 4.1996183\n",
      "0.25 0 425\n",
      "0.08235503 0.019728754 0.016646715 2.5822954 4.2180495\n",
      "0.25 0 450\n",
      "0.0945777 0.020381609 0.019219022 2.5393991 4.2069287\n",
      "0.25 0 475\n",
      "0.0916593 0.020172935 0.017232351 2.5208704 4.217732\n",
      "Building model with relu activation and 0.250 dropout\n",
      "0.25 1 0\n",
      "0.0437922 0.005206867 0.0032318835 4.5577908 4.6845994\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 304us/sample - loss: 4.3361 - mse: 4.3361\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1306 - mse: 4.1306\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.1080 - mse: 4.1080\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.0965 - mse: 4.0965\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.0559 - mse: 4.0559\n",
      "0.25 1 5\n",
      "0.045982447 0.0036357369 0.0028676041 3.8504488 4.250764\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9779 - mse: 3.9779\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9369 - mse: 3.9369\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9511 - mse: 3.9511\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8487 - mse: 3.8487\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8709 - mse: 3.8709\n",
      "0.25 1 10\n",
      "0.06188175 0.0035254203 0.0026446406 3.7466328 4.2212615\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8476 - mse: 3.8476\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8221 - mse: 3.8221\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8334 - mse: 3.8334\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8300 - mse: 3.8300\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8283 - mse: 3.8283\n",
      "0.25 1 15\n",
      "0.09410629 0.0040494064 0.0030201336 3.650769 4.1707473\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.7554 - mse: 3.7554\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7497 - mse: 3.7497\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7852 - mse: 3.7852\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7853 - mse: 3.7853\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7879 - mse: 3.7879\n",
      "0.25 1 20\n",
      "0.09463092 0.003835427 0.002903966 3.6223671 4.1366177\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.8178 - mse: 3.8178\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8085 - mse: 3.8085\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8390 - mse: 3.8390\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.6984 - mse: 3.6984\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.7789 - mse: 3.7789\n",
      "0.25 1 25\n",
      "0.1077556 0.0041484414 0.0030262046 3.5846224 4.119319\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7682 - mse: 3.7682\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7918 - mse: 3.7918\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7323 - mse: 3.7323\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.7722 - mse: 3.7722\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.6740 - mse: 3.6740\n",
      "0.25 1 30\n",
      "0.11494751 0.0041030413 0.0031959065 3.559354 4.1157436\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.7665 - mse: 3.7665\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 71us/sample - loss: 3.7026 - mse: 3.7026\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 3.7451 - mse: 3.7451\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.8151 - mse: 3.8151\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.7372 - mse: 3.7372\n",
      "0.25 1 35\n",
      "0.10623433 0.0042979163 0.0030661272 3.531691 4.1233406\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.6440 - mse: 3.6440\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.7450 - mse: 3.7450\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.6618 - mse: 3.6618\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.7165 - mse: 3.7165\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.8069 - mse: 3.8069\n",
      "0.25 1 40\n",
      "0.115363285 0.0045057964 0.0033947907 3.499013 4.132699\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.6617 - mse: 3.6617\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.6692 - mse: 3.6692\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7372 - mse: 3.7372\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7853 - mse: 3.7853\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.6230 - mse: 3.6230\n",
      "0.25 1 45\n",
      "0.119852416 0.004881047 0.003550129 3.4621775 4.1264815\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7227 - mse: 3.7227\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7189 - mse: 3.7189\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6725 - mse: 3.6725\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.6343 - mse: 3.6343\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.5791 - mse: 3.5791\n",
      "0.25 1 50\n",
      "0.12602143 0.004994452 0.004147851 3.4315982 4.1046534\n",
      "0.25 1 75\n",
      "0.14698364 0.0070981947 0.0069698812 3.2707074 4.120254\n",
      "0.25 1 100\n",
      "0.12904099 0.009403212 0.008737572 3.159635 4.12803\n",
      "0.25 1 125\n",
      "0.11858704 0.011016494 0.0100624785 3.0738876 4.1325226\n",
      "0.25 1 150\n",
      "0.1100691 0.012542807 0.011962699 2.9882267 4.1455164\n",
      "0.25 1 175\n",
      "0.10051865 0.013857318 0.012529469 2.9176123 4.14111\n",
      "0.25 1 200\n",
      "0.110470936 0.015508118 0.014817877 2.8284032 4.1512966\n",
      "0.25 1 225\n",
      "0.100422695 0.016081713 0.015966859 2.768423 4.1321917\n",
      "0.25 1 250\n",
      "0.083279245 0.014446316 0.015021793 2.7836127 4.1667347\n",
      "0.25 1 275\n",
      "0.08305122 0.01669854 0.01579165 2.7299411 4.2336144\n",
      "0.25 1 300\n",
      "0.09074046 0.0186739 0.016266875 2.6625748 4.2582984\n",
      "0.25 1 325\n",
      "0.08641001 0.01879633 0.017763492 2.6508148 4.2131014\n",
      "0.25 1 350\n",
      "0.08946647 0.019602468 0.018378895 2.5999606 4.2531385\n",
      "0.25 1 375\n",
      "0.09051296 0.019530417 0.017596712 2.600585 4.212637\n",
      "0.25 1 400\n",
      "0.07830188 0.01790039 0.01692603 2.6074867 4.2172847\n",
      "0.25 1 425\n",
      "0.07867737 0.01963912 0.017415937 2.5803502 4.2041655\n",
      "0.25 1 450\n",
      "0.08008908 0.018762508 0.017144097 2.5696492 4.2493196\n",
      "0.25 1 475\n",
      "0.08220239 0.018663319 0.018516568 2.5583954 4.195425\n",
      "Building model with relu activation and 0.250 dropout\n",
      "0.25 2 0\n",
      "0.049169105 0.0047236974 0.0036652405 4.790921 4.8512197\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 321us/sample - loss: 4.5676 - mse: 4.5676\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.2614 - mse: 4.2614\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0826 - mse: 4.0826\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0791 - mse: 4.0791\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0224 - mse: 4.0224\n",
      "0.25 2 5\n",
      "0.028355582 0.0035195535 0.0026822488 3.867888 4.18819\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0487 - mse: 4.0487\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0010 - mse: 4.0010\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8446 - mse: 3.8446\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 4.0360 - mse: 4.0360\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.9021 - mse: 3.9021\n",
      "0.25 2 10\n",
      "0.055366967 0.0038087291 0.0027817548 3.7457118 4.144858\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.9057 - mse: 3.9057\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.8864 - mse: 3.8864\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.8369 - mse: 3.8369\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.7932 - mse: 3.7932\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 3.8839 - mse: 3.8839\n",
      "0.25 2 15\n",
      "0.082192115 0.004137507 0.0031600595 3.66125 4.1040764\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8773 - mse: 3.8773\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7067 - mse: 3.7067\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8056 - mse: 3.8056\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8013 - mse: 3.8013\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.7867 - mse: 3.7867\n",
      "0.25 2 20\n",
      "0.110275574 0.004564499 0.003559339 3.6002524 4.069798\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.8385 - mse: 3.8385\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7043 - mse: 3.7043\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7647 - mse: 3.7647\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7623 - mse: 3.7623\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7224 - mse: 3.7224\n",
      "0.25 2 25\n",
      "0.117513895 0.005015789 0.0040082964 3.5552392 4.0451303\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.6504 - mse: 3.6504\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.7754 - mse: 3.7754\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.7499 - mse: 3.7499\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7431 - mse: 3.7431\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8608 - mse: 3.8608\n",
      "0.25 2 30\n",
      "0.11417444 0.0047795232 0.0036498276 3.5450678 4.0483184\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.7557 - mse: 3.7557\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.6980 - mse: 3.6980\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.7654 - mse: 3.7654\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.7327 - mse: 3.7327\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.6603 - mse: 3.6603\n",
      "0.25 2 35\n",
      "0.12072478 0.005136663 0.003907272 3.4958732 4.043518\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.6912 - mse: 3.6912\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.5889 - mse: 3.5889\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.6944 - mse: 3.6944\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.6869 - mse: 3.6869\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.6757 - mse: 3.6757\n",
      "0.25 2 40\n",
      "0.12070069 0.0050838827 0.003719175 3.4690661 4.0381765\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.7334 - mse: 3.7334\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.7328 - mse: 3.7328\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 3.6494 - mse: 3.6494\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.5691 - mse: 3.5691\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.6135 - mse: 3.6135\n",
      "0.25 2 45\n",
      "0.13264708 0.0061317966 0.0049440064 3.4248004 4.023122\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.6169 - mse: 3.6169\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.7224 - mse: 3.7224\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.6475 - mse: 3.6475\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.7446 - mse: 3.7446\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.6059 - mse: 3.6059\n",
      "0.25 2 50\n",
      "0.13275322 0.0061067273 0.004426748 3.4006853 4.0351686\n",
      "0.25 2 75\n",
      "0.12882082 0.0079602115 0.006857185 3.2891521 4.039223\n",
      "0.25 2 100\n",
      "0.12852749 0.009778152 0.008734013 3.1995184 4.0898314\n",
      "0.25 2 125\n",
      "0.12862226 0.012703798 0.011538672 3.083514 4.1026187\n",
      "0.25 2 150\n",
      "0.12758347 0.015101696 0.0147178285 2.9940555 4.1519227\n",
      "0.25 2 175\n",
      "0.12599105 0.018094562 0.01688645 2.8832414 4.156625\n",
      "0.25 2 200\n",
      "0.10287893 0.017613025 0.015734412 2.8609614 4.161961\n",
      "0.25 2 225\n",
      "0.102022104 0.019286219 0.017662745 2.7942622 4.1762977\n",
      "0.25 2 250\n",
      "0.09913872 0.018931534 0.016289352 2.754454 4.196314\n",
      "0.25 2 275\n",
      "0.10032878 0.019495307 0.017034622 2.7191393 4.1886334\n",
      "0.25 2 300\n",
      "0.10047036 0.020207975 0.018296335 2.6429565 4.1752872\n",
      "0.25 2 325\n",
      "0.09283596 0.018662002 0.018475378 2.6257591 4.1472864\n",
      "0.25 2 350\n",
      "0.08247992 0.017433599 0.016508428 2.6576862 4.174164\n",
      "0.25 2 375\n",
      "0.09825798 0.021707555 0.018858457 2.5737882 4.1758013\n",
      "0.25 2 400\n",
      "0.09583027 0.020480344 0.018304218 2.5483522 4.168177\n",
      "0.25 2 425\n",
      "0.09761775 0.023016626 0.019859117 2.5003824 4.233027\n",
      "0.25 2 450\n",
      "0.091112085 0.021127898 0.020424739 2.5058196 4.256515\n",
      "0.25 2 475\n",
      "0.08127846 0.020256218 0.019278016 2.532727 4.2060695\n",
      "Building model with relu activation and 0.375 dropout\n",
      "0.375 0 0\n",
      "0.031456776 0.004700566 0.0029764422 4.443991 4.6153426\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 380us/sample - loss: 4.5239 - mse: 4.5239\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.3761 - mse: 4.3761\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.4261 - mse: 4.4261\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1908 - mse: 4.1908\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1980 - mse: 4.1980\n",
      "0.375 0 5\n",
      "0.011015829 0.0026328946 0.0020672837 3.9645326 4.33875\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.1161 - mse: 4.1161\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.2024 - mse: 4.2024\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1477 - mse: 4.1477\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0219 - mse: 4.0219\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.0758 - mse: 4.0758\n",
      "0.375 0 10\n",
      "0.016632237 0.0020869388 0.0016520119 3.8806806 4.2844706\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0568 - mse: 4.0568\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 76us/sample - loss: 3.9897 - mse: 3.9897\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.9712 - mse: 3.9712\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.0284 - mse: 4.0284\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 3.9519 - mse: 3.9519\n",
      "0.375 0 15\n",
      "0.027369946 0.0021374705 0.0015755846 3.829053 4.252882\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9136 - mse: 3.9136\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9496 - mse: 3.9496\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9844 - mse: 3.9844\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9273 - mse: 3.9273\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 4.0905 - mse: 4.0905\n",
      "0.375 0 20\n",
      "0.026667822 0.0016865554 0.001450492 3.8377674 4.242751\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9185 - mse: 3.9185\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9669 - mse: 3.9669\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9467 - mse: 3.9467\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9088 - mse: 3.9088\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8900 - mse: 3.8900\n",
      "0.375 0 25\n",
      "0.039194696 0.0018929592 0.0013904439 3.7753272 4.2221785\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8759 - mse: 3.8759\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.9031 - mse: 3.9031\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8944 - mse: 3.8944\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8149 - mse: 3.8149\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8524 - mse: 3.8524\n",
      "0.375 0 30\n",
      "0.047500715 0.0019121537 0.0013776097 3.7480698 4.2094383\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9417 - mse: 3.9417\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9290 - mse: 3.9290\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8351 - mse: 3.8351\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.9497 - mse: 3.9497\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.7714 - mse: 3.7714\n",
      "0.375 0 35\n",
      "0.05081716 0.0020052972 0.0014645617 3.7084246 4.188284\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9339 - mse: 3.9339\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.8498 - mse: 3.8498\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.8225 - mse: 3.8225\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9436 - mse: 3.9436\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.8462 - mse: 3.8462\n",
      "0.375 0 40\n",
      "0.04562907 0.0018045582 0.0011836867 3.732834 4.194366\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7637 - mse: 3.7637\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8013 - mse: 3.8013\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8170 - mse: 3.8170\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8888 - mse: 3.8888\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8501 - mse: 3.8501\n",
      "0.375 0 45\n",
      "0.055308543 0.0019773706 0.0013299756 3.6949592 4.1819596\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8501 - mse: 3.8501\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8144 - mse: 3.8144\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8094 - mse: 3.8094\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8121 - mse: 3.8121\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.7598 - mse: 3.7598\n",
      "0.375 0 50\n",
      "0.05773081 0.001955334 0.0012831276 3.6786602 4.1713176\n",
      "0.375 0 75\n",
      "0.06941879 0.0023375347 0.0015977989 3.5947604 4.1454687\n",
      "0.375 0 100\n",
      "0.055941906 0.0022691905 0.0019162768 3.580139 4.139616\n",
      "0.375 0 125\n",
      "0.06014416 0.0028144554 0.0022927881 3.5446343 4.1391797\n",
      "0.375 0 150\n",
      "0.05978644 0.003243809 0.0026128208 3.5174334 4.1487284\n",
      "0.375 0 175\n",
      "0.067781314 0.004233601 0.0035701713 3.4527624 4.148265\n",
      "0.375 0 200\n",
      "0.056345873 0.0041904883 0.0031397766 3.4560924 4.159805\n",
      "0.375 0 225\n",
      "0.060341626 0.0045799804 0.003492553 3.4219756 4.132902\n",
      "0.375 0 250\n",
      "0.060364623 0.0044193007 0.0035046597 3.4079852 4.135938\n",
      "0.375 0 275\n",
      "0.052320458 0.0047462783 0.0036075676 3.392036 4.1667485\n",
      "0.375 0 300\n",
      "0.046905927 0.004872153 0.004176647 3.3727899 4.1669893\n",
      "0.375 0 325\n",
      "0.045904607 0.0050045634 0.004452555 3.3659708 4.18103\n",
      "0.375 0 350\n",
      "0.04644808 0.0054167435 0.0045198794 3.338295 4.1719418\n",
      "0.375 0 375\n",
      "0.045720298 0.005482631 0.004200704 3.344698 4.1719427\n",
      "0.375 0 400\n",
      "0.0534625 0.0061380127 0.0049452637 3.306811 4.170157\n",
      "0.375 0 425\n",
      "0.04907305 0.0056003253 0.0047561317 3.3142016 4.1733003\n",
      "0.375 0 450\n",
      "0.048262134 0.0052829734 0.0050009205 3.322098 4.19562\n",
      "0.375 0 475\n",
      "0.04263261 0.0057115234 0.004900207 3.3084059 4.206944\n",
      "Building model with relu activation and 0.375 dropout\n",
      "0.375 1 0\n",
      "0.05241322 0.0048718294 0.0029565399 5.8188424 5.6947722\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 298us/sample - loss: 5.2877 - mse: 5.2877\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.3694 - mse: 4.3694\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 4.2039 - mse: 4.2039\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 4.2798 - mse: 4.2798\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.0651 - mse: 4.0651\n",
      "0.375 1 5\n",
      "0.029250706 0.0024829493 0.0016408397 3.9218698 4.2140617\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1415 - mse: 4.1415\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0706 - mse: 4.0706\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.0210 - mse: 4.0210\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 4.1080 - mse: 4.1080\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 4.0673 - mse: 4.0673\n",
      "0.375 1 10\n",
      "0.02650083 0.0016279566 0.0012776643 3.8736303 4.18765\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0447 - mse: 4.0447\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9386 - mse: 3.9386\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9648 - mse: 3.9648\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9578 - mse: 3.9578\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.0523 - mse: 4.0523\n",
      "0.375 1 15\n",
      "0.030240959 0.0015020249 0.0010431886 3.8601415 4.1769295\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8944 - mse: 3.8944\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9627 - mse: 3.9627\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9848 - mse: 3.9848\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9949 - mse: 3.9949\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9797 - mse: 3.9797\n",
      "0.375 1 20\n",
      "0.031988 0.0013608496 0.0009396473 3.8326702 4.1575885\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9412 - mse: 3.9412\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9547 - mse: 3.9547\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.9001 - mse: 3.9001\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9773 - mse: 3.9773\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9512 - mse: 3.9512\n",
      "0.375 1 25\n",
      "0.03553296 0.0013908021 0.0009514961 3.7994714 4.1507645\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8706 - mse: 3.8706\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8778 - mse: 3.8778\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9204 - mse: 3.9204\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9560 - mse: 3.9560\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8395 - mse: 3.8395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.375 1 30\n",
      "0.044608597 0.0013563712 0.000933807 3.779665 4.139476\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8561 - mse: 3.8561\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8783 - mse: 3.8783\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8780 - mse: 3.8780\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9250 - mse: 3.9250\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8870 - mse: 3.8870\n",
      "0.375 1 35\n",
      "0.047931075 0.001445899 0.00090057 3.7678256 4.1416574\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8744 - mse: 3.8744\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8123 - mse: 3.8123\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.7820 - mse: 3.7820\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8462 - mse: 3.8462\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8808 - mse: 3.8808\n",
      "0.375 1 40\n",
      "0.06412878 0.0017594418 0.0011564804 3.706733 4.1243954\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9080 - mse: 3.9080\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9441 - mse: 3.9441\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8056 - mse: 3.8056\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8241 - mse: 3.8241\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8542 - mse: 3.8542\n",
      "0.375 1 45\n",
      "0.060591273 0.0016338219 0.0010669329 3.7085214 4.1261215\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8101 - mse: 3.8101\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.7656 - mse: 3.7656\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8196 - mse: 3.8196\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.8520 - mse: 3.8520\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8064 - mse: 3.8064\n",
      "0.375 1 50\n",
      "0.06030736 0.0017491698 0.0010008047 3.704376 4.12342\n",
      "0.375 1 75\n",
      "0.0750768 0.0023892743 0.0014190342 3.6259623 4.119003\n",
      "0.375 1 100\n",
      "0.07032323 0.002545527 0.0016573688 3.5912457 4.1342916\n",
      "0.375 1 125\n",
      "0.063394465 0.00266614 0.0018090849 3.5830357 4.121665\n",
      "0.375 1 150\n",
      "0.06910913 0.00314268 0.0027263782 3.5268185 4.11834\n",
      "0.375 1 175\n",
      "0.07030529 0.003964203 0.0029624219 3.48843 4.1198378\n",
      "0.375 1 200\n",
      "0.07340289 0.004055385 0.003376111 3.4471543 4.1238117\n",
      "0.375 1 225\n",
      "0.0638932 0.004245751 0.003720804 3.451096 4.1267447\n",
      "0.375 1 250\n",
      "0.06277463 0.004133268 0.0039559556 3.4238315 4.1183143\n",
      "0.375 1 275\n",
      "0.046498057 0.0038886948 0.0033108795 3.458876 4.130903\n",
      "0.375 1 300\n",
      "0.05027332 0.0046035834 0.003832164 3.4207788 4.133602\n",
      "0.375 1 325\n",
      "0.059162207 0.0053840936 0.004106086 3.376377 4.125619\n",
      "0.375 1 350\n",
      "0.06072688 0.005245655 0.004144513 3.3479173 4.1457934\n",
      "0.375 1 375\n",
      "0.055224787 0.005462599 0.0043745325 3.3551328 4.1572614\n",
      "0.375 1 400\n",
      "0.0556718 0.0056037465 0.0045220763 3.3367887 4.1334867\n",
      "0.375 1 425\n",
      "0.05589936 0.006040518 0.0051076273 3.3054898 4.1139674\n",
      "0.375 1 450\n",
      "0.05476886 0.0061137187 0.00486018 3.3224084 4.1211333\n",
      "0.375 1 475\n",
      "0.05576449 0.0061371573 0.0050862907 3.2855382 4.1075773\n",
      "Building model with relu activation and 0.375 dropout\n",
      "0.375 2 0\n",
      "0.01649367 0.0021480678 0.0016935751 4.6755953 4.7852364\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 1s 455us/sample - loss: 4.5399 - mse: 4.5399\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.2734 - mse: 4.2734\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.2426 - mse: 4.2426\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 4.1382 - mse: 4.1382\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.1662 - mse: 4.1662\n",
      "0.375 2 5\n",
      "0.0073085288 0.0018358544 0.0015157008 4.009303 4.290918\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.1794 - mse: 4.1794\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 4.0776 - mse: 4.0776\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 4.1608 - mse: 4.1608\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0622 - mse: 4.0622\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0775 - mse: 4.0775\n",
      "0.375 2 10\n",
      "0.011167849 0.001425287 0.0010896365 3.9568229 4.2379856\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0207 - mse: 4.0207\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.9882 - mse: 3.9882\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.9474 - mse: 3.9474\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.9018 - mse: 3.9018\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.9461 - mse: 3.9461\n",
      "0.375 2 15\n",
      "0.023653157 0.0017444771 0.0012580871 3.8469923 4.167175\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.9824 - mse: 3.9824\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.9165 - mse: 3.9165\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9483 - mse: 3.9483\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.0081 - mse: 4.0081\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 3.9794 - mse: 3.9794\n",
      "0.375 2 20\n",
      "0.027942883 0.0015173762 0.0010353229 3.834434 4.151074\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 3.9673 - mse: 3.9673\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9049 - mse: 3.9049\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.9072 - mse: 3.9072\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.8991 - mse: 3.8991\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9609 - mse: 3.9609\n",
      "0.375 2 25\n",
      "0.033776406 0.0015346362 0.0009794636 3.80971 4.1460714\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.9026 - mse: 3.9026\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.9162 - mse: 3.9162\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.8770 - mse: 3.8770\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9420 - mse: 3.9420\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.9670 - mse: 3.9670\n",
      "0.375 2 30\n",
      "0.042158067 0.001759215 0.0010644628 3.767191 4.123279\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8455 - mse: 3.8455\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8098 - mse: 3.8098\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8854 - mse: 3.8854\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.7938 - mse: 3.7938\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8914 - mse: 3.8914\n",
      "0.375 2 35\n",
      "0.058322866 0.0020179823 0.0011061992 3.7277184 4.0750685\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.8993 - mse: 3.8993\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8387 - mse: 3.8387\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.8128 - mse: 3.8128\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.8711 - mse: 3.8711\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8681 - mse: 3.8681\n",
      "0.375 2 40\n",
      "0.057865355 0.0019538235 0.0011112888 3.7210295 4.0788093\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9365 - mse: 3.9365\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9256 - mse: 3.9256\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8619 - mse: 3.8619\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8771 - mse: 3.8771\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8162 - mse: 3.8162\n",
      "0.375 2 45\n",
      "0.055308092 0.0019019953 0.001037121 3.7163815 4.097277\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8791 - mse: 3.8791\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8068 - mse: 3.8068\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8782 - mse: 3.8782\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8530 - mse: 3.8530\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.7907 - mse: 3.7907\n",
      "0.375 2 50\n",
      "0.063419335 0.002081562 0.0010021483 3.6915338 4.0901594\n",
      "0.375 2 75\n",
      "0.06558709 0.0019379786 0.0012812361 3.6406744 4.1282625\n",
      "0.375 2 100\n",
      "0.06844615 0.002516082 0.0016949753 3.5897183 4.1112137\n",
      "0.375 2 125\n",
      "0.066334836 0.002705305 0.0020689534 3.542849 4.126611\n",
      "0.375 2 150\n",
      "0.07723789 0.0038367405 0.0026909634 3.4757273 4.1184845\n",
      "0.375 2 175\n",
      "0.07660153 0.0043266295 0.0036510592 3.4252164 4.1131334\n",
      "0.375 2 200\n",
      "0.0629116 0.0039451914 0.003632885 3.4305298 4.13286\n",
      "0.375 2 225\n",
      "0.06878801 0.0052601723 0.004133766 3.3814588 4.1415105\n",
      "0.375 2 250\n",
      "0.0684864 0.005421524 0.004185226 3.358519 4.131708\n",
      "0.375 2 275\n",
      "0.061061986 0.005140183 0.004263555 3.3525777 4.1478977\n",
      "0.375 2 300\n",
      "0.054156203 0.0053464593 0.004339653 3.355629 4.1687417\n",
      "0.375 2 325\n",
      "0.055234045 0.0054860665 0.004494699 3.3371716 4.149601\n",
      "0.375 2 350\n",
      "0.05180797 0.005930138 0.0049727936 3.3137105 4.1704674\n",
      "0.375 2 375\n",
      "0.05427596 0.0068795425 0.005273945 3.2969446 4.170177\n",
      "0.375 2 400\n",
      "0.041799795 0.0054792175 0.004829574 3.3352184 4.1881485\n",
      "0.375 2 425\n",
      "0.044906702 0.0058201384 0.004974864 3.3005607 4.1470704\n",
      "0.375 2 450\n",
      "0.0518314 0.00611441 0.0050269393 3.282449 4.153273\n",
      "0.375 2 475\n",
      "0.04384324 0.005942472 0.0047861165 3.2908986 4.1641393\n",
      "Building model with relu activation and 0.500 dropout\n",
      "0.5 0 0\n",
      "0.056560036 0.005024154 0.0029429763 5.2511196 5.280783\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 280us/sample - loss: 5.4758 - mse: 5.4758\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.6942 - mse: 4.6942\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.5837 - mse: 4.5837\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.4539 - mse: 4.4539\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.4364 - mse: 4.4364\n",
      "0.5 0 5\n",
      "0.012390504 0.0016118616 0.0013788514 4.0674047 4.259148\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.3242 - mse: 4.3242\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.4155 - mse: 4.4155\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1390 - mse: 4.1390\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.2657 - mse: 4.2657\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1213 - mse: 4.1213\n",
      "0.5 0 10\n",
      "0.0097216405 0.0009815666 0.00082379923 4.0362577 4.252325\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1327 - mse: 4.1327\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1483 - mse: 4.1483\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1380 - mse: 4.1380\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1136 - mse: 4.1136\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0949 - mse: 4.0949\n",
      "0.5 0 15\n",
      "0.009531963 0.00077888503 0.0006201329 3.999842 4.2352414\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0688 - mse: 4.0688\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0806 - mse: 4.0806\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0399 - mse: 4.0399\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0442 - mse: 4.0442\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0213 - mse: 4.0213\n",
      "0.5 0 20\n",
      "0.008908709 0.0006475915 0.0005085159 3.9788928 4.238677\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0502 - mse: 4.0502\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0837 - mse: 4.0837\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0439 - mse: 4.0439\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9884 - mse: 3.9884\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9950 - mse: 3.9950\n",
      "0.5 0 25\n",
      "0.008642689 0.00055024645 0.00042278823 3.9577608 4.233732\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9559 - mse: 3.9559\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9617 - mse: 3.9617\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9718 - mse: 3.9718\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9932 - mse: 3.9932\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9451 - mse: 3.9451\n",
      "0.5 0 30\n",
      "0.010444757 0.0005377921 0.00041171492 3.932697 4.2146072\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9943 - mse: 3.9943\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0554 - mse: 4.0554\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9971 - mse: 3.9971\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9901 - mse: 3.9901\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0296 - mse: 4.0296\n",
      "0.5 0 35\n",
      "0.009744085 0.0004299705 0.00034304423 3.9321501 4.220391\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9559 - mse: 3.9559\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9606 - mse: 3.9606\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9711 - mse: 3.9711\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9807 - mse: 3.9807\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9619 - mse: 3.9619\n",
      "0.5 0 40\n",
      "0.012035487 0.00047784022 0.00033429774 3.898964 4.200808\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9267 - mse: 3.9267\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9435 - mse: 3.9435\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9682 - mse: 3.9682\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9332 - mse: 3.9332\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9971 - mse: 3.9971\n",
      "0.5 0 45\n",
      "0.013459992 0.00049241 0.0003241587 3.8859622 4.184566\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9273 - mse: 3.9273\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9536 - mse: 3.9536\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9761 - mse: 3.9761\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8803 - mse: 3.8803\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9113 - mse: 3.9113\n",
      "0.5 0 50\n",
      "0.015237018 0.0005068698 0.00033719317 3.8649123 4.183457\n",
      "0.5 0 75\n",
      "0.021587841 0.0005707981 0.00035104068 3.8200624 4.1638613\n",
      "0.5 0 100\n",
      "0.024777869 0.0006173223 0.00041129647 3.7922344 4.170028\n",
      "0.5 0 125\n",
      "0.0313688 0.000731454 0.0004529876 3.7468784 4.163185\n",
      "0.5 0 150\n",
      "0.024134573 0.00061597204 0.00040542355 3.7606301 4.1691337\n",
      "0.5 0 175\n",
      "0.026341114 0.0007208107 0.00048783474 3.7397027 4.1616564\n",
      "0.5 0 200\n",
      "0.03279178 0.00091900624 0.00061557675 3.7024245 4.1528645\n",
      "0.5 0 225\n",
      "0.021719407 0.0007308681 0.0005445442 3.7284262 4.1722283\n",
      "0.5 0 250\n",
      "0.026594276 0.00091054896 0.00062582723 3.6996632 4.1651783\n",
      "0.5 0 275\n",
      "0.031726435 0.0012442899 0.00085479085 3.6609375 4.155469\n",
      "0.5 0 300\n",
      "0.025986383 0.0011607023 0.0008216878 3.6713412 4.169542\n",
      "0.5 0 325\n",
      "0.023474498 0.0011927754 0.0009089943 3.6703897 4.164484\n",
      "0.5 0 350\n",
      "0.026125623 0.0014489499 0.0011147126 3.6451392 4.163185\n",
      "0.5 0 375\n",
      "0.023765543 0.0014969576 0.0012662138 3.639464 4.1651425\n",
      "0.5 0 400\n",
      "0.028498571 0.0016349148 0.0013475812 3.6135144 4.165298\n",
      "0.5 0 425\n",
      "0.023718461 0.0014898818 0.0013077847 3.6344128 4.1712985\n",
      "0.5 0 450\n",
      "0.023470296 0.0015790984 0.0014083696 3.6237895 4.1638293\n",
      "0.5 0 475\n",
      "0.017995985 0.0013335058 0.0011120389 3.6606154 4.174123\n",
      "Building model with relu activation and 0.500 dropout\n",
      "0.5 1 0\n",
      "0.035452966 0.004984482 0.0034392867 5.945038 5.8496485\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 294us/sample - loss: 6.2254 - mse: 6.2254\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.8544 - mse: 4.8545\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.6279 - mse: 4.6279\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.5527 - mse: 4.5527\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.4234 - mse: 4.4234\n",
      "0.5 1 5\n",
      "0.009975274 0.0022007045 0.001744706 4.0063705 4.254407\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.4889 - mse: 4.4889\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.2940 - mse: 4.2940\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.2974 - mse: 4.2974\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1530 - mse: 4.1530\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.1879 - mse: 4.1879\n",
      "0.5 1 10\n",
      "0.011331938 0.0015876956 0.0010436329 3.9689648 4.261067\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 79us/sample - loss: 4.1090 - mse: 4.1090\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1069 - mse: 4.1069\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.2445 - mse: 4.2445\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.1900 - mse: 4.1900\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1618 - mse: 4.1618\n",
      "0.5 1 15\n",
      "0.0086543895 0.0011108591 0.00071513443 3.9724288 4.2780714\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.1256 - mse: 4.1256\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.1097 - mse: 4.1097\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0563 - mse: 4.0563\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0490 - mse: 4.0490\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.0712 - mse: 4.0712\n",
      "0.5 1 20\n",
      "0.0088022 0.000856429 0.0005951446 3.9609873 4.267594\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 4.0819 - mse: 4.0819\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0421 - mse: 4.0421\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.0796 - mse: 4.0796\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0869 - mse: 4.0869\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0922 - mse: 4.0922\n",
      "0.5 1 25\n",
      "0.010031697 0.00072981516 0.00050545204 3.9344904 4.2456627\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0564 - mse: 4.0564\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0198 - mse: 4.0198\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0813 - mse: 4.0813\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9652 - mse: 3.9652\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0693 - mse: 4.0693\n",
      "0.5 1 30\n",
      "0.009682245 0.00064083043 0.0004299012 3.938355 4.236744\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 4.0216 - mse: 4.0216\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9873 - mse: 3.9873\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0238 - mse: 4.0238\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9417 - mse: 3.9417\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9963 - mse: 3.9963\n",
      "0.5 1 35\n",
      "0.011522741 0.00068112847 0.0003961326 3.9145339 4.223703\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.9795 - mse: 3.9795\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0453 - mse: 4.0453\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0566 - mse: 4.0566\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.9606 - mse: 3.9606\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0003 - mse: 4.0003\n",
      "0.5 1 40\n",
      "0.011208955 0.0006193236 0.00037349047 3.8952591 4.216957\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9757 - mse: 3.9757\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.0125 - mse: 4.0125\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9489 - mse: 3.9489\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0594 - mse: 4.0594\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9345 - mse: 3.9345\n",
      "0.5 1 45\n",
      "0.010465731 0.00054279144 0.0003135354 3.8924944 4.222982\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.9973 - mse: 3.9973\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9185 - mse: 3.9185\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.8996 - mse: 3.8996\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.8984 - mse: 3.8984\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.9672 - mse: 3.9672\n",
      "0.5 1 50\n",
      "0.013175476 0.0006375791 0.0003095084 3.8689106 4.2041926\n",
      "0.5 1 75\n",
      "0.020301776 0.00070360303 0.00033131833 3.8239627 4.168929\n",
      "0.5 1 100\n",
      "0.025151609 0.0008197399 0.0003080494 3.7959888 4.157424\n",
      "0.5 1 125\n",
      "0.025074583 0.0007908135 0.0003959919 3.7708411 4.15776\n",
      "0.5 1 150\n",
      "0.02620743 0.00077442615 0.00043648682 3.7552986 4.161326\n",
      "0.5 1 175\n",
      "0.024971815 0.0006943998 0.00044496165 3.7427616 4.168798\n",
      "0.5 1 200\n",
      "0.028472839 0.0008439496 0.00056210853 3.717927 4.164098\n",
      "0.5 1 225\n",
      "0.02546073 0.0008689338 0.0006108728 3.7210243 4.157464\n",
      "0.5 1 250\n",
      "0.02804314 0.0009927044 0.00069002 3.6901503 4.1505437\n",
      "0.5 1 275\n",
      "0.026368221 0.0010967152 0.0008178873 3.6782143 4.162045\n",
      "0.5 1 300\n",
      "0.02046814 0.0009891109 0.000730312 3.7020698 4.161035\n",
      "0.5 1 325\n",
      "0.023294969 0.0012811702 0.00081539556 3.6742837 4.1659884\n",
      "0.5 1 350\n",
      "0.018443579 0.0009880989 0.00076214207 3.702763 4.1806283\n",
      "0.5 1 375\n",
      "0.023833564 0.0013018547 0.0010088265 3.6511667 4.169146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1 400\n",
      "0.022849653 0.0013492547 0.0011559939 3.657411 4.1603413\n",
      "0.5 1 425\n",
      "0.024167374 0.0013676723 0.0012532623 3.6447322 4.1634836\n",
      "0.5 1 450\n",
      "0.025992213 0.0014675829 0.0012847616 3.6258216 4.1635017\n",
      "0.5 1 475\n",
      "0.028008353 0.0015797106 0.0013800889 3.6174455 4.150381\n",
      "Building model with relu activation and 0.500 dropout\n",
      "0.5 2 0\n",
      "0.020009467 0.0039776955 0.0026720795 4.6149516 4.7365613\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 1s 629us/sample - loss: 4.7005 - mse: 4.7005\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.5767 - mse: 4.5767\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 80us/sample - loss: 4.4064 - mse: 4.4064\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 127us/sample - loss: 4.2834 - mse: 4.2834\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 4.3401 - mse: 4.3401\n",
      "0.5 2 5\n",
      "0.009034031 0.0017377816 0.0012363256 4.0471387 4.300601\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 4.4080 - mse: 4.4080\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.2314 - mse: 4.2314\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.1880 - mse: 4.1880\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1698 - mse: 4.1698\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.0475 - mse: 4.0475\n",
      "0.5 2 10\n",
      "0.007988855 0.0010952732 0.0008671957 4.006239 4.282919\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1943 - mse: 4.1943\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1581 - mse: 4.1581\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0852 - mse: 4.0852\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1307 - mse: 4.1307\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0904 - mse: 4.0904\n",
      "0.5 2 15\n",
      "0.009102739 0.0009324808 0.000655872 3.9808698 4.2703934\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 77us/sample - loss: 4.0932 - mse: 4.0932\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 99us/sample - loss: 4.0823 - mse: 4.0823\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 4.1309 - mse: 4.1309\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0638 - mse: 4.0638\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 4.0178 - mse: 4.0178\n",
      "0.5 2 20\n",
      "0.010176036 0.0008114469 0.0005506594 3.9575117 4.2632384\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9669 - mse: 3.9669\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0778 - mse: 4.0778\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0424 - mse: 4.0424\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9163 - mse: 3.9163\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0126 - mse: 4.0126\n",
      "0.5 2 25\n",
      "0.008844019 0.0006659253 0.0004589117 3.9376945 4.242702\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0382 - mse: 4.0382\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 4.0023 - mse: 4.0023\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.0135 - mse: 4.0135\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 4.0370 - mse: 4.0370\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0632 - mse: 4.0632\n",
      "0.5 2 30\n",
      "0.008535139 0.0006060548 0.0003871314 3.9304583 4.2446203\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9428 - mse: 3.9428\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9822 - mse: 3.9822\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9579 - mse: 3.9579\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9665 - mse: 3.9665\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0466 - mse: 4.0466\n",
      "0.5 2 35\n",
      "0.011106993 0.00060066674 0.00039266085 3.9023793 4.220818\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9517 - mse: 3.9517\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9149 - mse: 3.9149\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9466 - mse: 3.9466\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9403 - mse: 3.9403\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0203 - mse: 4.0203\n",
      "0.5 2 40\n",
      "0.010315598 0.0005026787 0.00033377032 3.9068403 4.220643\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9049 - mse: 3.9049\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9721 - mse: 3.9721\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9768 - mse: 3.9768\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9755 - mse: 3.9755\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9164 - mse: 3.9164\n",
      "0.5 2 45\n",
      "0.009257538 0.00045389895 0.00028582377 3.9064515 4.2198596\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9754 - mse: 3.9754\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9562 - mse: 3.9562\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9701 - mse: 3.9701\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8966 - mse: 3.8966\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9262 - mse: 3.9262\n",
      "0.5 2 50\n",
      "0.01242227 0.0005556913 0.00035699783 3.8627682 4.1973963\n",
      "0.5 2 75\n",
      "0.01826561 0.000617811 0.00035443984 3.8144732 4.182293\n",
      "0.5 2 100\n",
      "0.028153991 0.000786219 0.00048789653 3.7556129 4.1601157\n",
      "0.5 2 125\n",
      "0.023237122 0.00074637425 0.00049666787 3.7535152 4.1735983\n",
      "0.5 2 150\n",
      "0.035694372 0.001013589 0.00067341403 3.6997805 4.158396\n",
      "0.5 2 175\n",
      "0.029447282 0.0009853774 0.00071238086 3.7079353 4.1699386\n",
      "0.5 2 200\n",
      "0.03390455 0.0011025836 0.0007630348 3.685437 4.1675158\n",
      "0.5 2 225\n",
      "0.026916608 0.0010071518 0.00071760826 3.6969414 4.1757503\n",
      "0.5 2 250\n",
      "0.030985668 0.0014015881 0.000842002 3.6777031 4.173935\n",
      "0.5 2 275\n",
      "0.027184863 0.0011759851 0.00080887944 3.6799748 4.180342\n",
      "0.5 2 300\n",
      "0.029305488 0.0013793651 0.0009014923 3.6715598 4.167237\n",
      "0.5 2 325\n",
      "0.03571312 0.0019449058 0.001380163 3.616174 4.168582\n",
      "0.5 2 350\n",
      "0.02654286 0.0013404817 0.0011437556 3.6564536 4.183259\n",
      "0.5 2 375\n",
      "0.026085852 0.0014499429 0.0011131975 3.6545565 4.1780887\n",
      "0.5 2 400\n",
      "0.025725635 0.0015163338 0.0011079158 3.6448255 4.1787505\n",
      "0.5 2 425\n",
      "0.021037992 0.0011943175 0.0010753439 3.6644974 4.1866207\n",
      "0.5 2 450\n",
      "0.02390906 0.0014452793 0.0012593117 3.6366892 4.183941\n",
      "0.5 2 475\n",
      "0.01986813 0.0013410056 0.0011885068 3.6505156 4.194511\n",
      "Building model with relu activation and 0.000 dropout\n",
      "0.0 0 0\n",
      "0.058676757 0.004990741 0.0035288497 4.379707 4.7155585\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 207us/sample - loss: 4.2266 - mse: 4.2266\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 4.0632 - mse: 4.0632\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.9818 - mse: 3.9818\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.9087 - mse: 3.9087\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.8404 - mse: 3.8404\n",
      "0.0 0 5\n",
      "0.074045874 0.005146754 0.0041334387 3.7811954 4.13157\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.7832 - mse: 3.7832\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.7300 - mse: 3.7300\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.6783 - mse: 3.6783\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.6275 - mse: 3.6275\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.5800 - mse: 3.5800\n",
      "0.0 0 10\n",
      "0.18984406 0.010799827 0.008192639 3.516146 4.164789\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.5260 - mse: 3.5260\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.4830 - mse: 3.4830\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 30us/sample - loss: 3.4352 - mse: 3.4352\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.3923 - mse: 3.3923\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.3485 - mse: 3.3485\n",
      "0.0 0 15\n",
      "0.2763176 0.01828368 0.016016385 3.275989 4.217417\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.2970 - mse: 3.2970\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.2465 - mse: 3.2465\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.2024 - mse: 3.2024\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.1634 - mse: 3.1634\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.1050 - mse: 3.1050\n",
      "0.0 0 20\n",
      "0.29568082 0.028471084 0.02429345 3.029489 4.2634635\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.0583 - mse: 3.0583\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.0035 - mse: 3.0035\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.9548 - mse: 2.9548\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.9052 - mse: 2.9052\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.8562 - mse: 2.8562\n",
      "0.0 0 25\n",
      "0.32799 0.04207299 0.038545184 2.7679136 4.3711624\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 2.8083 - mse: 2.8083\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.7542 - mse: 2.7542\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.7148 - mse: 2.7148\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.6795 - mse: 2.6795\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.6117 - mse: 2.6117\n",
      "0.0 0 30\n",
      "0.32271132 0.058133375 0.05859895 2.5194907 4.4919777\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.5485 - mse: 2.5485\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.5147 - mse: 2.5147\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.4582 - mse: 2.4582\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 30us/sample - loss: 2.4077 - mse: 2.4077\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.3607 - mse: 2.3607\n",
      "0.0 0 35\n",
      "0.32341993 0.079503454 0.079177305 2.2709274 4.5321326\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 2.3265 - mse: 2.3265\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 2.2747 - mse: 2.2747\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.2272 - mse: 2.2272\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.1885 - mse: 2.1885\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.1513 - mse: 2.1513\n",
      "0.0 0 40\n",
      "0.32343695 0.09833852 0.10162135 2.0535233 4.665912\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 2.1056 - mse: 2.1056\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.0611 - mse: 2.0611\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.0312 - mse: 2.0312\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 1.9781 - mse: 1.9781\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 1.9374 - mse: 1.9374\n",
      "0.0 0 45\n",
      "0.3324702 0.12092137 0.11381743 1.8522109 4.75621\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 1.9086 - mse: 1.9086\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 1.8686 - mse: 1.8686\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 1.8417 - mse: 1.8417\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 1.8195 - mse: 1.8195\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 1.7853 - mse: 1.7853\n",
      "0.0 0 50\n",
      "0.3435787 0.13988829 0.12947835 1.68887 4.820713\n",
      "0.0 0 75\n",
      "0.3655692 0.2195462 0.21093233 1.0767033 5.4823055\n",
      "0.0 0 100\n",
      "0.4082536 0.26188627 0.2638127 0.7291466 5.8929286\n",
      "0.0 0 125\n",
      "0.41599113 0.3178692 0.31450492 0.4839656 6.347991\n",
      "0.0 0 150\n",
      "0.44517055 0.35440123 0.36598986 0.33394453 6.686452\n",
      "0.0 0 175\n",
      "0.46236783 0.4147819 0.39523292 0.21685411 7.211463\n",
      "0.0 0 200\n",
      "0.47689268 0.44011152 0.4299669 0.15096226 7.710824\n",
      "0.0 0 225\n",
      "0.50425893 0.47018805 0.48401582 0.104385644 8.055984\n",
      "0.0 0 250\n",
      "0.50154835 0.48767808 0.5100775 0.07039103 8.330485\n",
      "0.0 0 275\n",
      "0.5321748 0.5099671 0.51845896 0.04848078 8.68024\n",
      "0.0 0 300\n",
      "0.5546321 0.5317013 0.52853245 0.039093167 8.930544\n",
      "0.0 0 325\n",
      "0.5487313 0.545987 0.5409919 0.030428901 9.048599\n",
      "0.0 0 350\n",
      "0.5387564 0.56645036 0.58322626 0.017420353 9.2936535\n",
      "0.0 0 375\n",
      "0.55867326 0.5716633 0.5753425 0.014334996 9.442927\n",
      "0.0 0 400\n",
      "0.55928904 0.60839033 0.5769046 0.010415423 9.548357\n",
      "0.0 0 425\n",
      "0.57451415 0.5956342 0.61508876 0.013128567 9.663438\n",
      "0.0 0 450\n",
      "0.5700181 0.60229963 0.5689507 0.0063838363 9.620806\n",
      "0.0 0 475\n",
      "0.55919427 0.60372764 0.5972166 0.022937218 9.573777\n",
      "Building model with relu activation and 0.000 dropout\n",
      "0.0 1 0\n",
      "0.03315741 0.0052980697 0.0037973449 4.2998 4.5326953\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 209us/sample - loss: 4.2123 - mse: 4.2123\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 4.0776 - mse: 4.0776\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.9986 - mse: 3.9986\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.9397 - mse: 3.9397\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 30us/sample - loss: 3.8791 - mse: 3.8791\n",
      "0.0 1 5\n",
      "0.059957158 0.0050971513 0.0036203247 3.8261275 4.257778\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.8226 - mse: 3.8226\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.7867 - mse: 3.7867\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.7392 - mse: 3.7391\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.6953 - mse: 3.6953\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 30us/sample - loss: 3.6568 - mse: 3.6568\n",
      "0.0 1 10\n",
      "0.16355559 0.009427389 0.007633197 3.5923316 4.342417\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.6114 - mse: 3.6114\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.5735 - mse: 3.5735\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.5293 - mse: 3.5293\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.4884 - mse: 3.4884\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.4460 - mse: 3.4460\n",
      "0.0 1 15\n",
      "0.23781657 0.014795547 0.012103097 3.3869214 4.4092174\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.4012 - mse: 3.4012\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.3677 - mse: 3.3677\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.3136 - mse: 3.3136\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.2733 - mse: 3.2733\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.2340 - mse: 3.2340\n",
      "0.0 1 20\n",
      "0.2880185 0.022404455 0.02117879 3.1718807 4.4493446\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.1873 - mse: 3.1873\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.1504 - mse: 3.1504\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.1080 - mse: 3.1080\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.0695 - mse: 3.0695\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.0263 - mse: 3.0263\n",
      "0.0 1 25\n",
      "0.29417723 0.033542387 0.030789575 2.9462721 4.511997\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.9641 - mse: 2.9641\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.9365 - mse: 2.9365\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.8920 - mse: 2.8920\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.8431 - mse: 2.8431\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.7896 - mse: 2.7896\n",
      "0.0 1 30\n",
      "0.32414612 0.047233205 0.04773734 2.712133 4.61678\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 2.7567 - mse: 2.7567\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.7149 - mse: 2.7149\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.6604 - mse: 2.6604\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.6286 - mse: 2.6286\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.5643 - mse: 2.5643\n",
      "0.0 1 35\n",
      "0.31711614 0.06655777 0.060368657 2.5247648 4.6629868\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 2.5441 - mse: 2.5441\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.4943 - mse: 2.4943\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.4654 - mse: 2.4654\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.4068 - mse: 2.4068\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.3825 - mse: 2.3825\n",
      "0.0 1 40\n",
      "0.30867618 0.08496851 0.079197355 2.2865326 4.825286\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 2.3431 - mse: 2.3431\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 2.2937 - mse: 2.2937\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.2628 - mse: 2.2628\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 2.2255 - mse: 2.2255\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 2.1943 - mse: 2.1943\n",
      "0.0 1 45\n",
      "0.32604757 0.101596825 0.0979396 2.1035252 4.9776163\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.1641 - mse: 2.1641\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.1249 - mse: 2.1249\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.0906 - mse: 2.0906\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.0711 - mse: 2.0711\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.0414 - mse: 2.0414\n",
      "0.0 1 50\n",
      "0.32821688 0.113231644 0.11212745 1.9404566 5.057072\n",
      "0.0 1 75\n",
      "0.35679302 0.17501841 0.18140861 1.3335303 5.721384\n",
      "0.0 1 100\n",
      "0.40457234 0.23012026 0.22294891 0.88661164 6.3784504\n",
      "0.0 1 125\n",
      "0.4043772 0.27402565 0.26972395 0.6246084 7.006278\n",
      "0.0 1 150\n",
      "0.43321475 0.30923763 0.3146207 0.4509949 7.5441375\n",
      "0.0 1 175\n",
      "0.46392086 0.34042603 0.36597544 0.33460575 7.9567995\n",
      "0.0 1 200\n",
      "0.47026622 0.39573193 0.40919757 0.23613034 8.3515835\n",
      "0.0 1 225\n",
      "0.5307068 0.43275034 0.42868218 0.17555651 8.781928\n",
      "0.0 1 250\n",
      "0.5458867 0.4518382 0.46450445 0.13277222 9.056337\n",
      "0.0 1 275\n",
      "0.5158158 0.49317247 0.47800624 0.101221584 9.241622\n",
      "0.0 1 300\n",
      "0.5363427 0.5020335 0.49603954 0.082679324 9.636827\n",
      "0.0 1 325\n",
      "0.5912933 0.52818185 0.5250207 0.062202245 9.963855\n",
      "0.0 1 350\n",
      "0.564963 0.54190177 0.5409375 0.05079306 10.123909\n",
      "0.0 1 375\n",
      "0.5480486 0.5442193 0.55868 0.030584412 10.361873\n",
      "0.0 1 400\n",
      "0.56481093 0.5787398 0.56200105 0.021791356 10.541695\n",
      "0.0 1 425\n",
      "0.56633455 0.5949101 0.58525354 0.020361692 10.885449\n",
      "0.0 1 450\n",
      "0.6098856 0.6083316 0.6076226 0.0227962 11.009006\n",
      "0.0 1 475\n",
      "0.6008844 0.63263875 0.605548 0.012467761 11.186625\n",
      "Building model with relu activation and 0.000 dropout\n",
      "0.0 2 0\n",
      "0.029087316 0.0030253397 0.0022831245 4.3091908 4.309348\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 210us/sample - loss: 4.2023 - mse: 4.2023\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 4.0651 - mse: 4.0651\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 4.0020 - mse: 4.0020\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.9493 - mse: 3.9493\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8932 - mse: 3.8932\n",
      "0.0 2 5\n",
      "0.039372798 0.0039297235 0.002758047 3.846523 4.276912\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.8429 - mse: 3.8429\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.7928 - mse: 3.7928\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.7364 - mse: 3.7364\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.6839 - mse: 3.6839\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.6398 - mse: 3.6398\n",
      "0.0 2 10\n",
      "0.13121061 0.01021554 0.006534372 3.569743 4.324207\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.5796 - mse: 3.5796\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 3.5290 - mse: 3.5290\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 30us/sample - loss: 3.4665 - mse: 3.4666\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 3.4214 - mse: 3.4214\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.3681 - mse: 3.3681\n",
      "0.0 2 15\n",
      "0.23667851 0.019184476 0.0144319 3.2977827 4.421836\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.3279 - mse: 3.3279\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.2719 - mse: 3.2719\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.2210 - mse: 3.2210\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 65us/sample - loss: 3.1625 - mse: 3.1625\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 88us/sample - loss: 3.1250 - mse: 3.1250\n",
      "0.0 2 20\n",
      "0.2878497 0.03139636 0.02622398 3.0387273 4.5438766\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.0626 - mse: 3.0626\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.0074 - mse: 3.0074\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 2.9631 - mse: 2.9631\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 2.9131 - mse: 2.9131\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 2.8555 - mse: 2.8555\n",
      "0.0 2 25\n",
      "0.3214448 0.04737086 0.04159826 2.776293 4.6224194\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 2.8151 - mse: 2.8151\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.7627 - mse: 2.7627\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.7077 - mse: 2.7077\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.6725 - mse: 2.6725\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 2.6140 - mse: 2.6140\n",
      "0.0 2 30\n",
      "0.34007382 0.06974367 0.057778258 2.51664 4.799201\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 2.5592 - mse: 2.5592\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.5069 - mse: 2.5069\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.4719 - mse: 2.4719\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.4134 - mse: 2.4134\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 2.3859 - mse: 2.3859\n",
      "0.0 2 35\n",
      "0.36726603 0.093408145 0.085111395 2.294122 5.0032487\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 2.3551 - mse: 2.3551\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 2.2886 - mse: 2.2886\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.2578 - mse: 2.2578\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 2.2146 - mse: 2.2146\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 2.1689 - mse: 2.1689\n",
      "0.0 2 40\n",
      "0.39127296 0.11387118 0.09663341 2.0799289 5.069539\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 2.1394 - mse: 2.1394\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 2.0924 - mse: 2.0924\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 2.0578 - mse: 2.0578\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 2.0220 - mse: 2.0220\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 2.0004 - mse: 2.0004\n",
      "0.0 2 45\n",
      "0.41200468 0.13406253 0.11923601 1.90373 5.2626367\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 1.9509 - mse: 1.9509\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 1.9126 - mse: 1.9126\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 32us/sample - loss: 1.8777 - mse: 1.8777\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 1.8696 - mse: 1.8696\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 31us/sample - loss: 1.8299 - mse: 1.8299\n",
      "0.0 2 50\n",
      "0.43381777 0.15309387 0.13293025 1.7438192 5.3717833\n",
      "0.0 2 75\n",
      "0.4723633 0.22059038 0.21119063 1.1326733 5.8727255\n",
      "0.0 2 100\n",
      "0.5214905 0.27140254 0.2829535 0.76287407 6.3411417\n",
      "0.0 2 125\n",
      "0.54559153 0.32251137 0.32441157 0.5264467 6.7712255\n",
      "0.0 2 150\n",
      "0.55183077 0.37006825 0.38760462 0.37258983 7.190545\n",
      "0.0 2 175\n",
      "0.61041325 0.4156582 0.41132724 0.2581809 7.683276\n",
      "0.0 2 200\n",
      "0.641358 0.45648322 0.45411035 0.18649036 8.121142\n",
      "0.0 2 225\n",
      "0.6595707 0.49734765 0.47251934 0.13366689 8.4533615\n",
      "0.0 2 250\n",
      "0.7016416 0.53327686 0.50271505 0.09487569 8.771754\n",
      "0.0 2 275\n",
      "0.7079347 0.5473985 0.5282133 0.07175987 8.988751\n",
      "0.0 2 300\n",
      "0.66683704 0.57498944 0.5586709 0.045162078 9.062419\n",
      "0.0 2 325\n",
      "0.7233564 0.5877614 0.6011046 0.03056074 9.351028\n",
      "0.0 2 350\n",
      "0.6977308 0.60844904 0.5871499 0.025924414 9.458164\n",
      "0.0 2 375\n",
      "0.7094624 0.62640613 0.59849685 0.017625194 9.532626\n",
      "0.0 2 400\n",
      "0.7126885 0.62302786 0.601681 0.015880466 9.6229725\n",
      "0.0 2 425\n",
      "0.77439284 0.6365793 0.6155127 0.020470696 9.750865\n",
      "0.0 2 450\n",
      "0.7493759 0.6293851 0.6247334 0.0140038505 9.833667\n",
      "0.0 2 475\n",
      "0.79718703 0.6397747 0.600001 0.038906217 9.85756\n",
      "Building model with relu activation and 0.125 dropout\n",
      "0.125 0 0\n",
      "0.07038377 0.0063144155 0.0036740608 4.2868953 4.565915\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 390us/sample - loss: 4.3298 - mse: 4.3298\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.1358 - mse: 4.1358\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 4.0833 - mse: 4.0833\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0226 - mse: 4.0226\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0157 - mse: 4.0157\n",
      "0.125 0 5\n",
      "0.037129305 0.0032382514 0.0024046768 3.9290903 4.1975\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0063 - mse: 4.0063\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9421 - mse: 3.9421\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9310 - mse: 3.9310\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9013 - mse: 3.9013\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8223 - mse: 3.8223\n",
      "0.125 0 10\n",
      "0.088736154 0.005401268 0.003688853 3.7832022 4.2006083\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.8964 - mse: 3.8964\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8027 - mse: 3.8027\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8146 - mse: 3.8146\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8669 - mse: 3.8669\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.7787 - mse: 3.7787\n",
      "0.125 0 15\n",
      "0.11328733 0.006820036 0.004850986 3.6721358 4.20343\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8107 - mse: 3.8107\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8305 - mse: 3.8305\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.7224 - mse: 3.7224\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8140 - mse: 3.8140\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7808 - mse: 3.7808\n",
      "0.125 0 20\n",
      "0.12739128 0.007539822 0.006421141 3.5896971 4.205869\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.7517 - mse: 3.7517\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8193 - mse: 3.8193\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7371 - mse: 3.7371\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7703 - mse: 3.7703\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7337 - mse: 3.7337\n",
      "0.125 0 25\n",
      "0.1264809 0.009036096 0.007407466 3.498574 4.2078524\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6815 - mse: 3.6815\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6703 - mse: 3.6703\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.6999 - mse: 3.6999\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.6127 - mse: 3.6127\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6060 - mse: 3.6060\n",
      "0.125 0 30\n",
      "0.15390244 0.012124962 0.009752799 3.388228 4.249473\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.5874 - mse: 3.5874\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.5786 - mse: 3.5786\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6530 - mse: 3.6530\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.6013 - mse: 3.6013\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.5832 - mse: 3.5832\n",
      "0.125 0 35\n",
      "0.14859957 0.01370569 0.01171478 3.2993152 4.239911\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.5178 - mse: 3.5178\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.5825 - mse: 3.5825\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.5295 - mse: 3.5295\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.4867 - mse: 3.4867\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.4904 - mse: 3.4904\n",
      "0.125 0 40\n",
      "0.15921865 0.01696751 0.015789004 3.1905134 4.2992754\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.4220 - mse: 3.4220\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.5013 - mse: 3.5013\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.5147 - mse: 3.5147\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.4807 - mse: 3.4807\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.4013 - mse: 3.4013\n",
      "0.125 0 45\n",
      "0.17457964 0.021273013 0.018183611 3.0813842 4.332668\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.4678 - mse: 3.4678\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.3507 - mse: 3.3507\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.4575 - mse: 3.4575\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.3950 - mse: 3.3950\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.3454 - mse: 3.3454\n",
      "0.125 0 50\n",
      "0.15517418 0.026832843 0.020407757 2.980843 4.3456726\n",
      "0.125 0 75\n",
      "0.14875793 0.043221064 0.03652746 2.5896857 4.401206\n",
      "0.125 0 100\n",
      "0.11859818 0.048370067 0.047424875 2.31024 4.5034165\n",
      "0.125 0 125\n",
      "0.15651871 0.055292003 0.052353345 2.0985281 4.615343\n",
      "0.125 0 150\n",
      "0.15286562 0.058557715 0.055837434 1.9395682 4.732242\n",
      "0.125 0 175\n",
      "0.14663665 0.056328338 0.05786655 1.8355994 4.6881723\n",
      "0.125 0 200\n",
      "0.15281126 0.061357453 0.06160877 1.7188535 4.727665\n",
      "0.125 0 225\n",
      "0.16290694 0.06443282 0.061930384 1.6209723 4.763219\n",
      "0.125 0 250\n",
      "0.14403903 0.061983928 0.06434881 1.5895157 4.7333198\n",
      "0.125 0 275\n",
      "0.154596 0.06308706 0.06376305 1.508278 4.8195534\n",
      "0.125 0 300\n",
      "0.1417853 0.06563319 0.05874369 1.4869753 4.7641587\n",
      "0.125 0 325\n",
      "0.15244551 0.0663106 0.06575194 1.4114351 4.8157134\n",
      "0.125 0 350\n",
      "0.14918934 0.063898 0.06547788 1.3636847 4.8559265\n",
      "0.125 0 375\n",
      "0.15605524 0.06528765 0.06262995 1.3593887 4.8481193\n",
      "0.125 0 400\n",
      "0.13273396 0.060079616 0.06416263 1.3542401 4.7631254\n",
      "0.125 0 425\n",
      "0.16463177 0.06762968 0.069786936 1.2711915 4.8973775\n",
      "0.125 0 450\n",
      "0.14238054 0.06056543 0.07013226 1.2606615 4.8595233\n",
      "0.125 0 475\n",
      "0.15294906 0.06480832 0.06621571 1.217499 4.871624\n",
      "Building model with relu activation and 0.125 dropout\n",
      "0.125 1 0\n",
      "0.032189675 0.0032073213 0.0023384462 4.245375 4.254078\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 280us/sample - loss: 4.2313 - mse: 4.2313\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.1042 - mse: 4.1042\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1087 - mse: 4.1087\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.1119 - mse: 4.1119\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0381 - mse: 4.0381\n",
      "0.125 1 5\n",
      "0.01863615 0.0017858606 0.0013662328 3.9987903 4.1864433\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 240us/sample - loss: 4.0296 - mse: 4.0296\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 255us/sample - loss: 3.9781 - mse: 3.9781\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 155us/sample - loss: 3.9622 - mse: 3.9622\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 94us/sample - loss: 3.9739 - mse: 3.9739\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 90us/sample - loss: 3.9432 - mse: 3.9432\n",
      "0.125 1 10\n",
      "0.052972972 0.0030960809 0.002373243 3.8563628 4.1599474\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8832 - mse: 3.8832\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8951 - mse: 3.8951\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9138 - mse: 3.9138\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 77us/sample - loss: 3.8481 - mse: 3.8481\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.7987 - mse: 3.7987\n",
      "0.125 1 15\n",
      "0.1213745 0.005778791 0.0040636244 3.7193315 4.167565\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.8013 - mse: 3.8013\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 108us/sample - loss: 3.8366 - mse: 3.8366\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.8420 - mse: 3.8420\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 95us/sample - loss: 3.7249 - mse: 3.7249\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 67us/sample - loss: 3.7613 - mse: 3.7613\n",
      "0.125 1 20\n",
      "0.16018814 0.0074894493 0.0055209473 3.6106992 4.228589\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7790 - mse: 3.7790\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7037 - mse: 3.7037\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.7527 - mse: 3.7527\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6665 - mse: 3.6665\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.6837 - mse: 3.6837\n",
      "0.125 1 25\n",
      "0.1797993 0.00957246 0.007827319 3.4963481 4.237863\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7659 - mse: 3.7659\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6382 - mse: 3.6382\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.6479 - mse: 3.6479\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.5659 - mse: 3.5659\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6037 - mse: 3.6037\n",
      "0.125 1 30\n",
      "0.1842285 0.011589435 0.009921608 3.3867583 4.240902\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 3.5526 - mse: 3.5526\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 3.6100 - mse: 3.6100\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.6069 - mse: 3.6069\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.6127 - mse: 3.6127\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.5892 - mse: 3.5892\n",
      "0.125 1 35\n",
      "0.19911718 0.0146633815 0.013565142 3.2760062 4.277383\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.5473 - mse: 3.5473\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.5024 - mse: 3.5024\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.5035 - mse: 3.5035\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.5271 - mse: 3.5271\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.4336 - mse: 3.4336\n",
      "0.125 1 40\n",
      "0.19721036 0.017355131 0.018267121 3.1683533 4.32776\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.4974 - mse: 3.4974\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.5526 - mse: 3.5526\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.5348 - mse: 3.5348\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.4556 - mse: 3.4556\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.4212 - mse: 3.4212\n",
      "0.125 1 45\n",
      "0.19427404 0.019789156 0.020715851 3.0805094 4.3169155\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.4127 - mse: 3.4127\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.3934 - mse: 3.3934\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.3224 - mse: 3.3224\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.3800 - mse: 3.3800\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.3819 - mse: 3.3819\n",
      "0.125 1 50\n",
      "0.19572943 0.0234852 0.02547966 2.9660997 4.332029\n",
      "0.125 1 75\n",
      "0.19675232 0.040212683 0.044192787 2.594897 4.4418783\n",
      "0.125 1 100\n",
      "0.1983345 0.051931232 0.048648693 2.3565135 4.5794897\n",
      "0.125 1 125\n",
      "0.16762 0.054459725 0.054717895 2.2038016 4.581108\n",
      "0.125 1 150\n",
      "0.18030167 0.05687664 0.05633244 2.038072 4.610192\n",
      "0.125 1 175\n",
      "0.18629621 0.065516636 0.06776326 1.8815775 4.642074\n",
      "0.125 1 200\n",
      "0.18767156 0.06381682 0.06752228 1.7649786 4.6844745\n",
      "0.125 1 225\n",
      "0.1708003 0.06756357 0.06635269 1.6974108 4.6795583\n",
      "0.125 1 250\n",
      "0.1748929 0.067383125 0.06770248 1.6398271 4.7651668\n",
      "0.125 1 275\n",
      "0.17435706 0.0656072 0.069693245 1.5933633 4.7661905\n",
      "0.125 1 300\n",
      "0.18534599 0.06606709 0.070468314 1.5352798 4.7634273\n",
      "0.125 1 325\n",
      "0.16758817 0.062292103 0.06710288 1.5128905 4.7516556\n",
      "0.125 1 350\n",
      "0.16140647 0.058388796 0.06800499 1.479446 4.8223724\n",
      "0.125 1 375\n",
      "0.19795196 0.06431366 0.072715625 1.4019834 4.8409724\n",
      "0.125 1 400\n",
      "0.16570444 0.060542896 0.06761477 1.375915 4.8149686\n",
      "0.125 1 425\n",
      "0.1688123 0.061414808 0.06739185 1.3608065 4.78573\n",
      "0.125 1 450\n",
      "0.15717828 0.06194397 0.0675102 1.3330445 4.8089433\n",
      "0.125 1 475\n",
      "0.17180204 0.06383396 0.07009232 1.2896762 4.8240833\n",
      "Building model with relu activation and 0.125 dropout\n",
      "0.125 2 0\n",
      "0.068157986 0.006383725 0.00363037 4.2281795 4.2835207\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 293us/sample - loss: 4.2549 - mse: 4.2549\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.1999 - mse: 4.1999\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1182 - mse: 4.1182\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0662 - mse: 4.0662\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0118 - mse: 4.0118\n",
      "0.125 2 5\n",
      "0.033179976 0.0032082442 0.002045438 3.9342752 4.1756864\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9675 - mse: 3.9675\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9794 - mse: 3.9794\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9595 - mse: 3.9595\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9226 - mse: 3.9226\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9314 - mse: 3.9314\n",
      "0.125 2 10\n",
      "0.07022308 0.0046548154 0.0030608042 3.7885811 4.1608295\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8865 - mse: 3.8865\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8293 - mse: 3.8293\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.8562 - mse: 3.8562\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8268 - mse: 3.8268\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8017 - mse: 3.8017\n",
      "0.125 2 15\n",
      "0.11788091 0.006936513 0.0043062437 3.6702595 4.1981606\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8123 - mse: 3.8123\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.8345 - mse: 3.8345\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.6712 - mse: 3.6712\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.7589 - mse: 3.7589\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.6806 - mse: 3.6806\n",
      "0.125 2 20\n",
      "0.13892439 0.008675967 0.005853305 3.5655391 4.229774\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.7274 - mse: 3.7274\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6666 - mse: 3.6666\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6596 - mse: 3.6596\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6743 - mse: 3.6743\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.6000 - mse: 3.6000\n",
      "0.125 2 25\n",
      "0.16482058 0.011726315 0.008053891 3.4609869 4.243149\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6801 - mse: 3.6801\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6045 - mse: 3.6045\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6557 - mse: 3.6557\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.6549 - mse: 3.6549\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.6736 - mse: 3.6736\n",
      "0.125 2 30\n",
      "0.15177646 0.013011142 0.008709794 3.3890326 4.256346\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.6545 - mse: 3.6545\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.6111 - mse: 3.6111\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.5756 - mse: 3.5756\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.5663 - mse: 3.5663\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.5713 - mse: 3.5713\n",
      "0.125 2 35\n",
      "0.16631678 0.015872352 0.0116641335 3.2902803 4.2646694\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.5175 - mse: 3.5175\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.5670 - mse: 3.5670\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.5352 - mse: 3.5352\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.6576 - mse: 3.6576\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.4314 - mse: 3.4314\n",
      "0.125 2 40\n",
      "0.17910251 0.018598448 0.015092113 3.2097301 4.3047943\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.4563 - mse: 3.4563\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.3977 - mse: 3.3977\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.5735 - mse: 3.5735\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.4388 - mse: 3.4388\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.4451 - mse: 3.4451\n",
      "0.125 2 45\n",
      "0.18003118 0.020759545 0.017134085 3.1311243 4.3229074\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.5281 - mse: 3.5281\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.3728 - mse: 3.3728\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.5469 - mse: 3.5469\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.4458 - mse: 3.4458\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.3513 - mse: 3.3513\n",
      "0.125 2 50\n",
      "0.19262522 0.02282444 0.020117605 3.0529158 4.3656707\n",
      "0.125 2 75\n",
      "0.16776362 0.03140356 0.026499359 2.7625325 4.4202247\n",
      "0.125 2 100\n",
      "0.19421767 0.041266058 0.0376168 2.4921424 4.4946346\n",
      "0.125 2 125\n",
      "0.1775953 0.044533815 0.041707214 2.2934663 4.4403005\n",
      "0.125 2 150\n",
      "0.18893126 0.04853454 0.045340076 2.1014986 4.5405774\n",
      "0.125 2 175\n",
      "0.17924212 0.052622724 0.050962366 1.9520366 4.496689\n",
      "0.125 2 200\n",
      "0.1512438 0.052191127 0.054771546 1.8485109 4.5103364\n",
      "0.125 2 225\n",
      "0.17322855 0.052011956 0.051081236 1.789752 4.513024\n",
      "0.125 2 250\n",
      "0.18787834 0.053132832 0.05473926 1.6320199 4.5635376\n",
      "0.125 2 275\n",
      "0.19184402 0.056035027 0.056011 1.5845392 4.577304\n",
      "0.125 2 300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1535888 0.05156567 0.049149428 1.5879792 4.4521236\n",
      "0.125 2 325\n",
      "0.19851944 0.056228075 0.053256933 1.5027804 4.620239\n",
      "0.125 2 350\n",
      "0.18098924 0.052744567 0.05337289 1.4719192 4.672629\n",
      "0.125 2 375\n",
      "0.16254714 0.05916286 0.055218987 1.419339 4.6361384\n",
      "0.125 2 400\n",
      "0.18065476 0.061413184 0.057295788 1.3624042 4.647802\n",
      "0.125 2 425\n",
      "0.17414512 0.05855594 0.059480134 1.3182044 4.58669\n",
      "0.125 2 450\n",
      "0.17372045 0.057062104 0.056554224 1.3277705 4.4993987\n",
      "0.125 2 475\n",
      "0.17890306 0.059817236 0.06062987 1.2727498 4.5622945\n",
      "Building model with relu activation and 0.250 dropout\n",
      "0.25 0 0\n",
      "0.048418444 0.004368585 0.0029347718 4.0900702 4.2575483\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 274us/sample - loss: 4.1705 - mse: 4.1705\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 4.1331 - mse: 4.1331\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 4.1449 - mse: 4.1449\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0836 - mse: 4.0836\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.1165 - mse: 4.1165\n",
      "0.25 0 5\n",
      "0.037723433 0.0024606793 0.0020755073 3.960681 4.2012205\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 4.0274 - mse: 4.0274\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 4.0142 - mse: 4.0142\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 4.0490 - mse: 4.0490\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0486 - mse: 4.0486\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0456 - mse: 4.0456\n",
      "0.25 0 10\n",
      "0.040098637 0.0024021617 0.0017995853 3.905922 4.1900544\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0185 - mse: 4.0185\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9946 - mse: 3.9946\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9460 - mse: 3.9460\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9417 - mse: 3.9417\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0243 - mse: 4.0243\n",
      "0.25 0 15\n",
      "0.045316704 0.0025218464 0.0017576932 3.8591597 4.191055\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.9946 - mse: 3.9946\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9133 - mse: 3.9133\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9252 - mse: 3.9252\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8590 - mse: 3.8590\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8701 - mse: 3.8701\n",
      "0.25 0 20\n",
      "0.0726113 0.0033234414 0.002343845 3.7842755 4.1938925\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8717 - mse: 3.8717\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.9292 - mse: 3.9292\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8750 - mse: 3.8750\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8876 - mse: 3.8876\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9132 - mse: 3.9132\n",
      "0.25 0 25\n",
      "0.08790248 0.003811844 0.0026499266 3.741622 4.2249007\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 3.8259 - mse: 3.8259\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.8798 - mse: 3.8798\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8185 - mse: 3.8185\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8366 - mse: 3.8366\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8633 - mse: 3.8633\n",
      "0.25 0 30\n",
      "0.098631434 0.0045472565 0.0030679863 3.6910126 4.20775\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8363 - mse: 3.8363\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8182 - mse: 3.8182\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9163 - mse: 3.9163\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8009 - mse: 3.8009\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8944 - mse: 3.8944\n",
      "0.25 0 35\n",
      "0.09380348 0.0048956666 0.0035128265 3.6615999 4.2075944\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8369 - mse: 3.8369\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 3.8751 - mse: 3.8751\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.7774 - mse: 3.7774\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8626 - mse: 3.8626\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.9214 - mse: 3.9214\n",
      "0.25 0 40\n",
      "0.10363699 0.005630047 0.0040631737 3.6154435 4.239305\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8026 - mse: 3.8026\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.8622 - mse: 3.8622\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 3.9080 - mse: 3.9080\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.8063 - mse: 3.8063\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.8331 - mse: 3.8331\n",
      "0.25 0 45\n",
      "0.09226401 0.00651663 0.00388434 3.595382 4.2723227\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.8665 - mse: 3.8665\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.7088 - mse: 3.7088\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 34us/sample - loss: 3.7739 - mse: 3.7739\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8066 - mse: 3.8066\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 36us/sample - loss: 3.7561 - mse: 3.7561\n",
      "0.25 0 50\n",
      "0.091792315 0.007400261 0.004996828 3.5425336 4.2594337\n",
      "0.25 0 75\n",
      "0.10416478 0.010999373 0.008423188 3.3524332 4.290206\n",
      "0.25 0 100\n",
      "0.10296912 0.0147630675 0.011403995 3.217188 4.3489676\n",
      "0.25 0 125\n",
      "0.10344321 0.016212402 0.015684223 3.10453 4.345686\n",
      "0.25 0 150\n",
      "0.088388175 0.017862275 0.016490096 3.0398836 4.3505435\n",
      "0.25 0 175\n",
      "0.09179447 0.018737104 0.016994018 2.9825408 4.284918\n",
      "0.25 0 200\n",
      "0.083486356 0.01915905 0.017500898 2.9378743 4.3033285\n",
      "0.25 0 225\n",
      "0.085857265 0.019791499 0.017525144 2.9053078 4.29674\n",
      "0.25 0 250\n",
      "0.08170715 0.0196838 0.01997247 2.8533494 4.331156\n",
      "0.25 0 275\n",
      "0.08035138 0.019234037 0.018100953 2.8473039 4.3449507\n",
      "0.25 0 300\n",
      "0.08074171 0.021396445 0.019989068 2.7704887 4.3636885\n",
      "0.25 0 325\n",
      "0.081022926 0.021114904 0.020018512 2.7344706 4.3908873\n",
      "0.25 0 350\n",
      "0.07335283 0.01952264 0.01826208 2.7526457 4.3773036\n",
      "0.25 0 375\n",
      "0.0856133 0.021907462 0.01884379 2.6757188 4.402091\n",
      "0.25 0 400\n",
      "0.07898025 0.020964079 0.019760974 2.6817846 4.398039\n",
      "0.25 0 425\n",
      "0.081063196 0.02281939 0.020107593 2.6515763 4.396776\n",
      "0.25 0 450\n",
      "0.07606096 0.023734055 0.020803094 2.6432934 4.3939133\n",
      "0.25 0 475\n",
      "0.077097476 0.021318723 0.019755557 2.6533718 4.437214\n",
      "Building model with relu activation and 0.250 dropout\n",
      "0.25 1 0\n",
      "0.028033733 0.003750465 0.0024082016 4.2866163 4.2343946\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 266us/sample - loss: 4.3029 - mse: 4.3029\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.2605 - mse: 4.2605\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.1175 - mse: 4.1175\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 33us/sample - loss: 4.1270 - mse: 4.1270\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 35us/sample - loss: 4.0898 - mse: 4.0898\n",
      "0.25 1 5\n",
      "0.013828824 0.0017715167 0.0012677403 4.00353 4.2364597\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 81us/sample - loss: 4.0530 - mse: 4.0530\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 115us/sample - loss: 4.0220 - mse: 4.0220\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.1107 - mse: 4.1107\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.0414 - mse: 4.0414\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 77us/sample - loss: 4.0773 - mse: 4.0773\n",
      "0.25 1 10\n",
      "0.021802695 0.0018377819 0.001279606 3.9381683 4.2010245\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 4.0523 - mse: 4.0523\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 81us/sample - loss: 3.9742 - mse: 3.9742\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.9927 - mse: 3.9927\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0349 - mse: 4.0349\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.9497 - mse: 3.9497\n",
      "0.25 1 15\n",
      "0.048480384 0.002721051 0.0020722663 3.8523033 4.215458\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.9200 - mse: 3.9200\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9786 - mse: 3.9786\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9752 - mse: 3.9752\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 4.0331 - mse: 4.0331\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.9352 - mse: 3.9352\n",
      "0.25 1 20\n",
      "0.05930883 0.0030405791 0.0023811099 3.8033655 4.204635\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 142us/sample - loss: 3.8976 - mse: 3.8976\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 3.9422 - mse: 3.9422\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 79us/sample - loss: 3.9449 - mse: 3.9449\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 188us/sample - loss: 3.9287 - mse: 3.9287\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 92us/sample - loss: 3.9622 - mse: 3.9622\n",
      "0.25 1 25\n",
      "0.06740789 0.0033374596 0.0025911755 3.7621112 4.2173533\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9199 - mse: 3.9199\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9146 - mse: 3.9146\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.8639 - mse: 3.8639\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9114 - mse: 3.9114\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.8558 - mse: 3.8558\n",
      "0.25 1 30\n",
      "0.08479202 0.0043769013 0.003267839 3.7170868 4.249321\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8708 - mse: 3.8708\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.8708 - mse: 3.8708\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.7902 - mse: 3.7902\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.7807 - mse: 3.7807\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9247 - mse: 3.9247\n",
      "0.25 1 35\n",
      "0.104497336 0.0055327667 0.004325818 3.6633646 4.2347527\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9229 - mse: 3.9229\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7752 - mse: 3.7752\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.8379 - mse: 3.8379\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.8971 - mse: 3.8971\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.8669 - mse: 3.8669\n",
      "0.25 1 40\n",
      "0.085210815 0.0050083213 0.0038927433 3.6506789 4.2427793\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.8403 - mse: 3.8403\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9117 - mse: 3.9117\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8490 - mse: 3.8490\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.8446 - mse: 3.8446\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9249 - mse: 3.9249\n",
      "0.25 1 45\n",
      "0.09278269 0.005708452 0.0042026695 3.616368 4.26275\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.8524 - mse: 3.8524\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.7675 - mse: 3.7675\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7964 - mse: 3.7964\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.7931 - mse: 3.7931\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.8203 - mse: 3.8203\n",
      "0.25 1 50\n",
      "0.09274642 0.0063173524 0.005331057 3.5790572 4.284011\n",
      "0.25 1 75\n",
      "0.09234374 0.00887228 0.0073080612 3.4285295 4.2989893\n",
      "0.25 1 100\n",
      "0.09441347 0.013544699 0.010721534 3.271803 4.3036394\n",
      "0.25 1 125\n",
      "0.09848504 0.015360196 0.015446205 3.1554816 4.297697\n",
      "0.25 1 150\n",
      "0.09044005 0.017774243 0.015386484 3.0933487 4.296927\n",
      "0.25 1 175\n",
      "0.08158127 0.019498182 0.015191898 3.0413616 4.294108\n",
      "0.25 1 200\n",
      "0.07779021 0.0186546 0.015550857 2.9969134 4.2854776\n",
      "0.25 1 225\n",
      "0.087468415 0.021579415 0.018182406 2.9003286 4.3112826\n",
      "0.25 1 250\n",
      "0.09074182 0.02290284 0.020740176 2.837018 4.3039885\n",
      "0.25 1 275\n",
      "0.078818 0.021932123 0.018255264 2.8323967 4.310852\n",
      "0.25 1 300\n",
      "0.0894411 0.022541944 0.021779994 2.745436 4.3287263\n",
      "0.25 1 325\n",
      "0.07810847 0.021452637 0.019230202 2.7526765 4.3126044\n",
      "0.25 1 350\n",
      "0.07681641 0.023253761 0.019534826 2.7081406 4.3096647\n",
      "0.25 1 375\n",
      "0.07871122 0.023414666 0.01852122 2.6945493 4.292614\n",
      "0.25 1 400\n",
      "0.08131063 0.022144618 0.021466348 2.6729844 4.3150835\n",
      "0.25 1 425\n",
      "0.0881536 0.025712537 0.023070864 2.605055 4.300432\n",
      "0.25 1 450\n",
      "0.09342521 0.026854547 0.023236072 2.586783 4.3388257\n",
      "0.25 1 475\n",
      "0.08132457 0.027229974 0.022926215 2.578042 4.2941504\n",
      "Building model with relu activation and 0.250 dropout\n",
      "0.25 2 0\n",
      "0.036188163 0.0040556113 0.0030606189 4.1939487 4.3524017\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 432us/sample - loss: 4.2886 - mse: 4.2886\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.2162 - mse: 4.2162\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1359 - mse: 4.1359\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 4.1183 - mse: 4.1183\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.0661 - mse: 4.0661\n",
      "0.25 2 5\n",
      "0.015839893 0.0017338295 0.0013815975 3.9993012 4.218683\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 4.0583 - mse: 4.0583\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 4.0382 - mse: 4.0382\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 3.9745 - mse: 3.9745\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 4.0238 - mse: 4.0238\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.9861 - mse: 3.9861\n",
      "0.25 2 10\n",
      "0.03371396 0.002255088 0.001595935 3.8998933 4.175821\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9384 - mse: 3.9384\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9678 - mse: 3.9678\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 3.9652 - mse: 3.9652\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9387 - mse: 3.9387\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9281 - mse: 3.9281\n",
      "0.25 2 15\n",
      "0.061551604 0.0032744515 0.0020193467 3.820724 4.1916595\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0166 - mse: 4.0166\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9463 - mse: 3.9463\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9178 - mse: 3.9178\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9189 - mse: 3.9189\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9756 - mse: 3.9756\n",
      "0.25 2 20\n",
      "0.07317811 0.0035178005 0.0023217998 3.7761784 4.1664343\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.8714 - mse: 3.8714\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9062 - mse: 3.9062\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0048 - mse: 4.0048\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9235 - mse: 3.9235\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.8982 - mse: 3.8982\n",
      "0.25 2 25\n",
      "0.06527886 0.0033780925 0.0023416264 3.7541537 4.1600327\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8993 - mse: 3.8993\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8483 - mse: 3.8483\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.8999 - mse: 3.8999\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9017 - mse: 3.9017\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8830 - mse: 3.8830\n",
      "0.25 2 30\n",
      "0.07932429 0.0038723073 0.0025564148 3.7114315 4.1401896\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.8497 - mse: 3.8497\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.9055 - mse: 3.9055\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.8508 - mse: 3.8508\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.8468 - mse: 3.8468\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.8879 - mse: 3.8879\n",
      "0.25 2 35\n",
      "0.08331659 0.0043480126 0.0027641088 3.6738238 4.143396\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.7946 - mse: 3.7946\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8541 - mse: 3.8541\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8210 - mse: 3.8210\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.8152 - mse: 3.8152\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.7363 - mse: 3.7363\n",
      "0.25 2 40\n",
      "0.10738296 0.005607956 0.0034494416 3.6020675 4.1378436\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.8712 - mse: 3.8712\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.7965 - mse: 3.7965\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.8353 - mse: 3.8353\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 122us/sample - loss: 3.7710 - mse: 3.7710\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 3.7233 - mse: 3.7233\n",
      "0.25 2 45\n",
      "0.11035078 0.0060950792 0.0043080645 3.5638788 4.153718\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 68us/sample - loss: 3.8553 - mse: 3.8553\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 3.8436 - mse: 3.8436\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.7390 - mse: 3.7390\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.8847 - mse: 3.8847\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.7414 - mse: 3.7414\n",
      "0.25 2 50\n",
      "0.10713532 0.006329716 0.0048635206 3.5291588 4.1568584\n",
      "0.25 2 75\n",
      "0.120733276 0.010426313 0.0073116366 3.352402 4.185426\n",
      "0.25 2 100\n",
      "0.099803284 0.011909451 0.0100764865 3.2607894 4.242581\n",
      "0.25 2 125\n",
      "0.1139548 0.017077066 0.014141367 3.1073828 4.2465253\n",
      "0.25 2 150\n",
      "0.10047674 0.017548725 0.014413997 3.0628195 4.2565393\n",
      "0.25 2 175\n",
      "0.094228104 0.017857512 0.015984533 2.982335 4.2813945\n",
      "0.25 2 200\n",
      "0.10866726 0.020457711 0.01754513 2.9121168 4.372213\n",
      "0.25 2 225\n",
      "0.09506425 0.01855157 0.017199725 2.9086049 4.3275275\n",
      "0.25 2 250\n",
      "0.08585977 0.019338358 0.017746307 2.8497424 4.3659315\n",
      "0.25 2 275\n",
      "0.08478881 0.019077657 0.019137587 2.7918859 4.3707547\n",
      "0.25 2 300\n",
      "0.08333618 0.020242007 0.01933511 2.769618 4.380649\n",
      "0.25 2 325\n",
      "0.07523175 0.018117193 0.01749534 2.7751346 4.3527265\n",
      "0.25 2 350\n",
      "0.07819364 0.019863142 0.017931666 2.7438269 4.349419\n",
      "0.25 2 375\n",
      "0.080241896 0.020517135 0.019482214 2.6825504 4.34134\n",
      "0.25 2 400\n",
      "0.07604619 0.020294169 0.018165011 2.6887417 4.342026\n",
      "0.25 2 425\n",
      "0.06974625 0.01931955 0.017326588 2.6629 4.367325\n",
      "0.25 2 450\n",
      "0.06962274 0.0201413 0.018071752 2.6384017 4.3504133\n",
      "0.25 2 475\n",
      "0.07560361 0.0212437 0.019635564 2.5785043 4.368629\n",
      "Building model with relu activation and 0.375 dropout\n",
      "0.375 0 0\n",
      "0.04326397 0.004743503 0.0031793297 4.2510295 4.2793474\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 318us/sample - loss: 4.5179 - mse: 4.5179\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.3631 - mse: 4.3631\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.2327 - mse: 4.2327\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.2120 - mse: 4.2120\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.2017 - mse: 4.2017\n",
      "0.375 0 5\n",
      "0.010504981 0.0016725822 0.0013685216 4.0315366 4.2267385\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 4.1780 - mse: 4.1780\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1628 - mse: 4.1628\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1444 - mse: 4.1444\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1256 - mse: 4.1256\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1651 - mse: 4.1651\n",
      "0.375 0 10\n",
      "0.009839216 0.0011456748 0.0009124173 4.0036225 4.2027345\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0787 - mse: 4.0787\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1326 - mse: 4.1326\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1378 - mse: 4.1378\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0873 - mse: 4.0873\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1306 - mse: 4.1306\n",
      "0.375 0 15\n",
      "0.011816397 0.0010365663 0.0006973239 3.984477 4.222028\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 4.0851 - mse: 4.0851\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1015 - mse: 4.1015\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0491 - mse: 4.0491\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0285 - mse: 4.0285\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0165 - mse: 4.0165\n",
      "0.375 0 20\n",
      "0.01353474 0.0010531374 0.0007185464 3.9573889 4.204358\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9878 - mse: 3.9878\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0559 - mse: 4.0559\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0441 - mse: 4.0441\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9814 - mse: 3.9814\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0494 - mse: 4.0494\n",
      "0.375 0 25\n",
      "0.02104526 0.0012279361 0.00080183306 3.9247487 4.1984973\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0321 - mse: 4.0321\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0306 - mse: 4.0306\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.0404 - mse: 4.0404\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9792 - mse: 3.9792\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0313 - mse: 4.0313\n",
      "0.375 0 30\n",
      "0.022229705 0.0013125588 0.00077359896 3.911152 4.1853895\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0186 - mse: 4.0186\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9603 - mse: 3.9603\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0008 - mse: 4.0008\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9631 - mse: 3.9631\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9884 - mse: 3.9884\n",
      "0.375 0 35\n",
      "0.032839525 0.0017062149 0.0011413817 3.878072 4.181771\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9885 - mse: 3.9885\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9781 - mse: 3.9781\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9031 - mse: 3.9031\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0186 - mse: 4.0186\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 4.0073 - mse: 4.0073\n",
      "0.375 0 40\n",
      "0.034625255 0.0016811367 0.0011629324 3.8632119 4.1825275\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9671 - mse: 3.9671\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9006 - mse: 3.9006\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0036 - mse: 4.0036\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 3.9596 - mse: 3.9596\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0311 - mse: 4.0311\n",
      "0.375 0 45\n",
      "0.032920226 0.0017189217 0.0010005875 3.8575869 4.190366\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9921 - mse: 3.9921\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9904 - mse: 3.9904\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9413 - mse: 3.9413\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9320 - mse: 3.9320\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9504 - mse: 3.9504\n",
      "0.375 0 50\n",
      "0.038192783 0.0019874943 0.0012721292 3.8337739 4.1847563\n",
      "0.375 0 75\n",
      "0.04276405 0.0024057887 0.0016194412 3.770932 4.196098\n",
      "0.375 0 100\n",
      "0.042618927 0.0026587807 0.0017726498 3.727911 4.201027\n",
      "0.375 0 125\n",
      "0.050489366 0.0036069276 0.0024517789 3.658586 4.1782618\n",
      "0.375 0 150\n",
      "0.039433494 0.003405941 0.0026101754 3.6470346 4.161146\n",
      "0.375 0 175\n",
      "0.04097722 0.004523865 0.0033945213 3.5938506 4.175666\n",
      "0.375 0 200\n",
      "0.04139172 0.004961415 0.0038608 3.5613868 4.150244\n",
      "0.375 0 225\n",
      "0.039062623 0.0050354237 0.0046395683 3.5301461 4.163676\n",
      "0.375 0 250\n",
      "0.03066244 0.004524568 0.003928373 3.5453577 4.148325\n",
      "0.375 0 275\n",
      "0.0381943 0.0060444763 0.00551267 3.4642913 4.1536126\n",
      "0.375 0 300\n",
      "0.030746631 0.0050425706 0.00427667 3.508435 4.1504097\n",
      "0.375 0 325\n",
      "0.029562103 0.0053111296 0.0050332337 3.4677613 4.1522923\n",
      "0.375 0 350\n",
      "0.031702567 0.0051745316 0.00527565 3.457613 4.1503963\n",
      "0.375 0 375\n",
      "0.024992745 0.0050676726 0.0047855317 3.4671478 4.1472073\n",
      "0.375 0 400\n",
      "0.029292693 0.0055041933 0.0050774626 3.4303463 4.1430373\n",
      "0.375 0 425\n",
      "0.026418723 0.005440479 0.0050239777 3.4249127 4.1238594\n",
      "0.375 0 450\n",
      "0.027406912 0.0058591515 0.005416102 3.4015598 4.1537857\n",
      "0.375 0 475\n",
      "0.029029956 0.0057329433 0.0059350086 3.3801494 4.1410117\n",
      "Building model with relu activation and 0.375 dropout\n",
      "0.375 1 0\n",
      "0.041556958 0.0068893693 0.0055883043 4.3771744 4.6264324\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 320us/sample - loss: 4.6530 - mse: 4.6530\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.3708 - mse: 4.3708\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 4.3457 - mse: 4.3457\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.3079 - mse: 4.3079\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.3856 - mse: 4.3856\n",
      "0.375 1 5\n",
      "0.008605474 0.0017354707 0.001491187 4.0677185 4.187713\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 74us/sample - loss: 4.2050 - mse: 4.2050\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.3437 - mse: 4.3437\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.1414 - mse: 4.1414\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 4.1409 - mse: 4.1409\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.1407 - mse: 4.1407\n",
      "0.375 1 10\n",
      "0.008137736 0.0010127348 0.00088989973 4.028491 4.187263\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 4.1042 - mse: 4.1042\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.0897 - mse: 4.0897\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.1052 - mse: 4.1052\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.1008 - mse: 4.1008\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0904 - mse: 4.0904\n",
      "0.375 1 15\n",
      "0.0097207865 0.0008355984 0.0007207005 4.007844 4.187021\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 4.0498 - mse: 4.0498\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.0653 - mse: 4.0653\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 4.0678 - mse: 4.0678\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 4.0725 - mse: 4.0725\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0863 - mse: 4.0863\n",
      "0.375 1 20\n",
      "0.012060271 0.0008430853 0.00074178877 3.9811823 4.195582\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.0376 - mse: 4.0376\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 56us/sample - loss: 4.0558 - mse: 4.0558\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 4.0590 - mse: 4.0590\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 4.0348 - mse: 4.0348\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 4.0900 - mse: 4.0900\n",
      "0.375 1 25\n",
      "0.017325433 0.0009920484 0.0007312964 3.9499831 4.187364\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 83us/sample - loss: 4.0393 - mse: 4.0393\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 4.0458 - mse: 4.0458\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9956 - mse: 3.9956\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 3.9931 - mse: 3.9931\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 3.9520 - mse: 3.9520\n",
      "0.375 1 30\n",
      "0.022660235 0.0010725298 0.00084821053 3.9239879 4.180474\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0791 - mse: 4.0791\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0100 - mse: 4.0100\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0155 - mse: 4.0155\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.9787 - mse: 3.9787\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0321 - mse: 4.0321\n",
      "0.375 1 35\n",
      "0.0228867 0.0010638464 0.0007392555 3.9176502 4.159488\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.9629 - mse: 3.9629\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9481 - mse: 3.9481\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9525 - mse: 3.9525\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0359 - mse: 4.0359\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.0320 - mse: 4.0320\n",
      "0.375 1 40\n",
      "0.023105742 0.0011668298 0.0007547924 3.8999298 4.161178\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 69us/sample - loss: 3.9734 - mse: 3.9734\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 94us/sample - loss: 4.0375 - mse: 4.0375\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 4.0038 - mse: 4.0038\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.9789 - mse: 3.9789\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 3.9975 - mse: 3.9975\n",
      "0.375 1 45\n",
      "0.023309546 0.0011534777 0.00073711714 3.8933802 4.167759\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 3.8920 - mse: 3.8920\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.9427 - mse: 3.9427\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9327 - mse: 3.9327\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 3.9873 - mse: 3.9873\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 3.9699 - mse: 3.9699\n",
      "0.375 1 50\n",
      "0.032480244 0.0014744936 0.0009853533 3.8570373 4.161633\n",
      "0.375 1 75\n",
      "0.042325504 0.002307743 0.0014106486 3.7820292 4.1493363\n",
      "0.375 1 100\n",
      "0.0331855 0.0023346522 0.0017842819 3.742947 4.1582646\n",
      "0.375 1 125\n",
      "0.037101436 0.0027762665 0.0020022166 3.6875443 4.156681\n",
      "0.375 1 150\n",
      "0.038442884 0.0029850719 0.0022830963 3.6543906 4.14987\n",
      "0.375 1 175\n",
      "0.03457915 0.003425187 0.0030341158 3.618799 4.142938\n",
      "0.375 1 200\n",
      "0.037620578 0.0036566986 0.0028744382 3.595694 4.120794\n",
      "0.375 1 225\n",
      "0.03358586 0.0038129357 0.003669332 3.5597396 4.126508\n",
      "0.375 1 250\n",
      "0.04577364 0.0056528724 0.004562555 3.500956 4.102046\n",
      "0.375 1 275\n",
      "0.034602277 0.004848207 0.0038187248 3.5209775 4.1229253\n",
      "0.375 1 300\n",
      "0.035344273 0.0047299843 0.0038334213 3.5098803 4.1306868\n",
      "0.375 1 325\n",
      "0.03493359 0.0059211296 0.0049685594 3.460949 4.148545\n",
      "0.375 1 350\n",
      "0.032582365 0.0055254116 0.004706437 3.4711757 4.1532726\n",
      "0.375 1 375\n",
      "0.036808264 0.006178471 0.0049997484 3.4462302 4.157197\n",
      "0.375 1 400\n",
      "0.0299511 0.005620308 0.0047629187 3.460898 4.1502495\n",
      "0.375 1 425\n",
      "0.03758283 0.00686754 0.005651819 3.4223814 4.151175\n",
      "0.375 1 450\n",
      "0.032980684 0.0064458754 0.005049569 3.4300947 4.154353\n",
      "0.375 1 475\n",
      "0.030114625 0.0059778946 0.0055352 3.4328454 4.1550064\n",
      "Building model with relu activation and 0.375 dropout\n",
      "0.375 2 0\n",
      "0.019581147 0.0019345487 0.0013058728 4.125072 4.326453\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 331us/sample - loss: 4.2452 - mse: 4.2452\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.1637 - mse: 4.1637\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1578 - mse: 4.1578\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 54us/sample - loss: 4.0838 - mse: 4.0838\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 4.1397 - mse: 4.1397\n",
      "0.375 2 5\n",
      "0.005512147 0.0008886745 0.0006497135 4.0528636 4.1855636\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 58us/sample - loss: 4.0960 - mse: 4.0960\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 4.1252 - mse: 4.1252\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.1173 - mse: 4.1173\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.1431 - mse: 4.1431\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.0908 - mse: 4.0908\n",
      "0.375 2 10\n",
      "0.00650714 0.0007761817 0.0005851117 4.02523 4.180859\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 61us/sample - loss: 4.0827 - mse: 4.0827\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 4.0525 - mse: 4.0525\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 4.0531 - mse: 4.0531\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.0609 - mse: 4.0609\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0628 - mse: 4.0628\n",
      "0.375 2 15\n",
      "0.009962617 0.0010643296 0.0006300851 3.986699 4.174739\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 74us/sample - loss: 4.0411 - mse: 4.0411\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 77us/sample - loss: 4.1130 - mse: 4.1130\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0367 - mse: 4.0367\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0850 - mse: 4.0850\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 72us/sample - loss: 4.0769 - mse: 4.0769\n",
      "0.375 2 20\n",
      "0.010871686 0.0010469768 0.0006442762 3.966807 4.1729217\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 82us/sample - loss: 4.0044 - mse: 4.0044\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 66us/sample - loss: 4.0452 - mse: 4.0452\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 60us/sample - loss: 4.0428 - mse: 4.0428\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.0236 - mse: 4.0236\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 3.9932 - mse: 3.9932\n",
      "0.375 2 25\n",
      "0.01718519 0.0012306806 0.0007544225 3.9304943 4.16014\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 64us/sample - loss: 4.0497 - mse: 4.0497\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 69us/sample - loss: 4.0048 - mse: 4.0048\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 70us/sample - loss: 4.0770 - mse: 4.0770\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 3.9785 - mse: 3.9785\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 59us/sample - loss: 4.0575 - mse: 4.0575\n",
      "0.375 2 30\n",
      "0.02078096 0.0013969389 0.0008128073 3.9166927 4.152707\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 74us/sample - loss: 4.0498 - mse: 4.0498\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.0432 - mse: 4.0432\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0088 - mse: 4.0088\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.0473 - mse: 4.0473\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.0313 - mse: 4.0313\n",
      "0.375 2 35\n",
      "0.018395402 0.0012609058 0.0007334735 3.9179509 4.14822\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 52us/sample - loss: 3.9193 - mse: 3.9193\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 57us/sample - loss: 3.9721 - mse: 3.9721\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 3.9224 - mse: 3.9224\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 51us/sample - loss: 4.0269 - mse: 4.0269\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.0072 - mse: 4.0072\n",
      "0.375 2 40\n",
      "0.028053558 0.0017793003 0.0008846466 3.8792026 4.1435924\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.0170 - mse: 4.0170\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 3.9410 - mse: 3.9410\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 3.9926 - mse: 3.9926\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 3.9501 - mse: 3.9501\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 3.9722 - mse: 3.9722\n",
      "0.375 2 45\n",
      "0.034380253 0.001938629 0.0011165449 3.8513293 4.1371393\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 3.9022 - mse: 3.9022\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9281 - mse: 3.9281\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.8607 - mse: 3.8607\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 3.9881 - mse: 3.9881\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 3.9491 - mse: 3.9491\n",
      "0.375 2 50\n",
      "0.03977605 0.0022991605 0.0012760918 3.825125 4.1376023\n",
      "0.375 2 75\n",
      "0.03697223 0.002260419 0.0014816062 3.7790372 4.1349545\n",
      "0.375 2 100\n",
      "0.037555203 0.002281311 0.0019017488 3.7370956 4.1473894\n",
      "0.375 2 125\n",
      "0.042829733 0.0032094552 0.0025759456 3.6738667 4.150081\n",
      "0.375 2 150\n",
      "0.04371006 0.0037178712 0.0029463288 3.63405 4.1480165\n",
      "0.375 2 175\n",
      "0.0418679 0.004072312 0.0033273976 3.608912 4.1337285\n",
      "0.375 2 200\n",
      "0.047584496 0.004836601 0.004299827 3.5393937 4.157109\n",
      "0.375 2 225\n",
      "0.04386442 0.0052519552 0.0045905123 3.522382 4.1623826\n",
      "0.375 2 250\n",
      "0.045646533 0.00699141 0.005682575 3.4744172 4.185965\n",
      "0.375 2 275\n",
      "0.03956816 0.0062056906 0.005314159 3.485584 4.182658\n",
      "0.375 2 300\n",
      "0.0448763 0.0072927065 0.0058440035 3.4517915 4.1766386\n",
      "0.375 2 325\n",
      "0.040544707 0.0072850846 0.005729596 3.442349 4.1814\n",
      "0.375 2 350\n",
      "0.04462319 0.0071553253 0.00592243 3.4232922 4.199547\n",
      "0.375 2 375\n",
      "0.037042372 0.006682161 0.005571704 3.4387648 4.197732\n",
      "0.375 2 400\n",
      "0.03728172 0.006614949 0.005375726 3.4155185 4.1982303\n",
      "0.375 2 425\n",
      "0.03934795 0.0072735413 0.0061976863 3.3878212 4.1934953\n",
      "0.375 2 450\n",
      "0.033669647 0.006720861 0.0056527853 3.4293745 4.167386\n",
      "0.375 2 475\n",
      "0.03746298 0.0069888458 0.0061788773 3.3826904 4.1783605\n",
      "Building model with relu activation and 0.500 dropout\n",
      "0.5 0 0\n",
      "0.060488988 0.005461683 0.003570774 4.261152 4.265131\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 278us/sample - loss: 4.9277 - mse: 4.9277\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 88us/sample - loss: 4.8458 - mse: 4.8458\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.3997 - mse: 4.3997\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.5874 - mse: 4.5874\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.3952 - mse: 4.3952\n",
      "0.5 0 5\n",
      "0.003945824 0.00093367824 0.00088492146 4.11082 4.2036605\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.3571 - mse: 4.3571\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.4126 - mse: 4.4126\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.3897 - mse: 4.3897\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.2230 - mse: 4.2230\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.1988 - mse: 4.1988\n",
      "0.5 0 10\n",
      "0.0017556851 0.00041816774 0.00042029028 4.084289 4.199016\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.2110 - mse: 4.2110\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1907 - mse: 4.1907\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1911 - mse: 4.1911\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1513 - mse: 4.1513\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1263 - mse: 4.1263\n",
      "0.5 0 15\n",
      "0.0010119244 0.00028270492 0.00027029138 4.079402 4.2041607\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1106 - mse: 4.1106\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.2253 - mse: 4.2253\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.1566 - mse: 4.1566\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1846 - mse: 4.1846\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1534 - mse: 4.1534\n",
      "0.5 0 20\n",
      "0.00083669793 0.00019120554 0.00018833707 4.0811934 4.1961036\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1751 - mse: 4.1751\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.1235 - mse: 4.1235\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 55us/sample - loss: 4.1559 - mse: 4.1559\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1550 - mse: 4.1550\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1542 - mse: 4.1542\n",
      "0.5 0 25\n",
      "0.0006565574 0.00013104401 0.00013454098 4.0776296 4.2057285\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0603 - mse: 4.0603\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0828 - mse: 4.0828\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.0977 - mse: 4.0977\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.1270 - mse: 4.1270\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1328 - mse: 4.1328\n",
      "0.5 0 30\n",
      "0.0008156599 0.00013087003 0.00012673748 4.073936 4.209308\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1224 - mse: 4.1224\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1166 - mse: 4.1166\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1209 - mse: 4.1209\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0642 - mse: 4.0642\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.1131 - mse: 4.1131\n",
      "0.5 0 35\n",
      "0.0009732683 0.000117692565 0.00011236298 4.069835 4.2093573\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1179 - mse: 4.1179\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0773 - mse: 4.0773\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0970 - mse: 4.0970\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0672 - mse: 4.0672\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1248 - mse: 4.1248\n",
      "0.5 0 40\n",
      "0.0013426706 0.00012262652 0.000112569775 4.062921 4.2147593\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.0915 - mse: 4.0915\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0452 - mse: 4.0452\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1072 - mse: 4.1072\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0787 - mse: 4.0787\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0811 - mse: 4.0811\n",
      "0.5 0 45\n",
      "0.0024074994 0.00015439949 0.0001229713 4.050592 4.211161\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0627 - mse: 4.0627\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0200 - mse: 4.0200\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0852 - mse: 4.0852\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0927 - mse: 4.0927\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0637 - mse: 4.0637\n",
      "0.5 0 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0040383786 0.00020649999 0.00016470575 4.033863 4.2124434\n",
      "0.5 0 75\n",
      "0.005662379 0.0001995628 0.00013146427 4.011575 4.2033668\n",
      "0.5 0 100\n",
      "0.010513874 0.00038699064 0.00024520792 3.9670699 4.2128706\n",
      "0.5 0 125\n",
      "0.010872328 0.00038350408 0.00024329525 3.9527621 4.1985283\n",
      "0.5 0 150\n",
      "0.015516379 0.0006806056 0.00037801222 3.9197552 4.1914253\n",
      "0.5 0 175\n",
      "0.01990517 0.00082228414 0.00048645 3.890981 4.1849117\n",
      "0.5 0 200\n",
      "0.014659462 0.0006280044 0.00042339164 3.9008324 4.199204\n",
      "0.5 0 225\n",
      "0.0146785155 0.0007295618 0.00054300996 3.8857353 4.1902137\n",
      "0.5 0 250\n",
      "0.013723794 0.0008050523 0.00062646496 3.8762486 4.193377\n",
      "0.5 0 275\n",
      "0.015697293 0.0010752241 0.00078800536 3.848453 4.1781673\n",
      "0.5 0 300\n",
      "0.016618488 0.001412542 0.0009772162 3.8258185 4.1787496\n",
      "0.5 0 325\n",
      "0.019886354 0.0013402277 0.0010632008 3.8079736 4.1795306\n",
      "0.5 0 350\n",
      "0.013469403 0.0010937102 0.00078732846 3.8435516 4.189919\n",
      "0.5 0 375\n",
      "0.015848469 0.0013823843 0.0009819161 3.810707 4.1765847\n",
      "0.5 0 400\n",
      "0.015268314 0.0013156765 0.0010420299 3.8091223 4.178885\n",
      "0.5 0 425\n",
      "0.013859416 0.0014009727 0.0010822993 3.8166237 4.19025\n",
      "0.5 0 450\n",
      "0.013976977 0.0013817966 0.0010380968 3.8039205 4.1919746\n",
      "0.5 0 475\n",
      "0.018375773 0.0017719693 0.0012354909 3.7720053 4.190811\n",
      "Building model with relu activation and 0.500 dropout\n",
      "0.5 1 0\n",
      "0.03740043 0.003804023 0.002635415 4.2279387 4.281153\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 284us/sample - loss: 4.6941 - mse: 4.6941\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.5142 - mse: 4.5142\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.3797 - mse: 4.3797\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.3877 - mse: 4.3877\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.3477 - mse: 4.3477\n",
      "0.5 1 5\n",
      "0.0058223284 0.00086760113 0.00070165703 4.0807114 4.2802997\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.2821 - mse: 4.2821\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1728 - mse: 4.1728\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1580 - mse: 4.1580\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.2615 - mse: 4.2615\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1412 - mse: 4.1412\n",
      "0.5 1 10\n",
      "0.0027122283 0.0004411368 0.00034488284 4.0694695 4.256253\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.2106 - mse: 4.2106\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1626 - mse: 4.1626\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1680 - mse: 4.1680\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1441 - mse: 4.1441\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.1977 - mse: 4.1977\n",
      "0.5 1 15\n",
      "0.0019143459 0.00030353866 0.00023166346 4.0682316 4.2477846\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.1247 - mse: 4.1247\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.1740 - mse: 4.1740\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1063 - mse: 4.1063\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1263 - mse: 4.1263\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 47us/sample - loss: 4.0667 - mse: 4.0667\n",
      "0.5 1 20\n",
      "0.0019274404 0.00023275524 0.00018619494 4.0616007 4.2324376\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1612 - mse: 4.1612\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1046 - mse: 4.1046\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0997 - mse: 4.0997\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0719 - mse: 4.0719\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1044 - mse: 4.1044\n",
      "0.5 1 25\n",
      "0.0025251808 0.0002486239 0.00016854315 4.055043 4.2355933\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0807 - mse: 4.0807\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0901 - mse: 4.0901\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0398 - mse: 4.0398\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1231 - mse: 4.1231\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0772 - mse: 4.0772\n",
      "0.5 1 30\n",
      "0.0031638865 0.00022235695 0.00015646029 4.049735 4.2207623\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.0895 - mse: 4.0895\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0936 - mse: 4.0936\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0648 - mse: 4.0648\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0485 - mse: 4.0485\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1099 - mse: 4.1099\n",
      "0.5 1 35\n",
      "0.003449832 0.0002194298 0.00015123648 4.041568 4.216855\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.0620 - mse: 4.0620\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1019 - mse: 4.1019\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0627 - mse: 4.0627\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 53us/sample - loss: 4.0148 - mse: 4.0148\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0424 - mse: 4.0424\n",
      "0.5 1 40\n",
      "0.004546932 0.0002747983 0.0001877264 4.027124 4.2081056\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0955 - mse: 4.0955\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0595 - mse: 4.0595\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 62us/sample - loss: 4.0791 - mse: 4.0791\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.1009 - mse: 4.1009\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0507 - mse: 4.0507\n",
      "0.5 1 45\n",
      "0.004367925 0.00024703436 0.0001536 4.0267076 4.2102027\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 50us/sample - loss: 4.0618 - mse: 4.0618\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 48us/sample - loss: 4.0632 - mse: 4.0632\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 49us/sample - loss: 4.0837 - mse: 4.0837\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.0911 - mse: 4.0911\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0346 - mse: 4.0346\n",
      "0.5 1 50\n",
      "0.0052839103 0.00025054396 0.00017134294 4.0158844 4.2074585\n",
      "0.5 1 75\n",
      "0.010915265 0.00035761239 0.00023225592 3.9718723 4.1877637\n",
      "0.5 1 100\n",
      "0.014107523 0.00049908686 0.00028049183 3.9528003 4.190615\n",
      "0.5 1 125\n",
      "0.019369394 0.0006410853 0.0004094695 3.917235 4.1850905\n",
      "0.5 1 150\n",
      "0.022742383 0.00084453565 0.00053747284 3.8897173 4.168313\n",
      "0.5 1 175\n",
      "0.018690515 0.000798817 0.00059230253 3.8846805 4.180074\n",
      "0.5 1 200\n",
      "0.01571801 0.00075000495 0.00055053923 3.8885646 4.173265\n",
      "0.5 1 225\n",
      "0.021047417 0.0011829021 0.00087845954 3.8341806 4.1673756\n",
      "0.5 1 250\n",
      "0.01721583 0.0010561522 0.0008113412 3.8438299 4.166566\n",
      "0.5 1 275\n",
      "0.014422517 0.0010109551 0.00077580335 3.8502278 4.170782\n",
      "0.5 1 300\n",
      "0.01503833 0.0011003916 0.00074617483 3.8400187 4.1765904\n",
      "0.5 1 325\n",
      "0.020227065 0.0015993854 0.0011826443 3.7900608 4.1831803\n",
      "0.5 1 350\n",
      "0.019124713 0.0015113788 0.0010697537 3.796156 4.1887026\n",
      "0.5 1 375\n",
      "0.016021412 0.0012789859 0.0010134655 3.8089383 4.193439\n",
      "0.5 1 400\n",
      "0.01728645 0.0015177558 0.0010927069 3.7868698 4.178647\n",
      "0.5 1 425\n",
      "0.016851185 0.001547715 0.0011389727 3.781484 4.172397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 1 450\n",
      "0.012964378 0.0013170547 0.0010217763 3.80381 4.181562\n",
      "0.5 1 475\n",
      "0.013058115 0.0014635447 0.0011601541 3.7895443 4.1758075\n",
      "Building model with relu activation and 0.500 dropout\n",
      "0.5 2 0\n",
      "0.038341973 0.0035022406 0.002469839 4.1124372 4.279432\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 270us/sample - loss: 4.6678 - mse: 4.6678\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.2821 - mse: 4.2821\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.3575 - mse: 4.3575\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.2202 - mse: 4.2202\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1914 - mse: 4.1914\n",
      "0.5 2 5\n",
      "0.007258709 0.0007243836 0.00064325234 4.054098 4.2512193\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.2180 - mse: 4.2180\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1934 - mse: 4.1934\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1545 - mse: 4.1545\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1296 - mse: 4.1296\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.1784 - mse: 4.1784\n",
      "0.5 2 10\n",
      "0.004587772 0.00034503225 0.00029626512 4.0522704 4.234378\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.1189 - mse: 4.1189\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1069 - mse: 4.1069\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.1127 - mse: 4.1127\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1304 - mse: 4.1304\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.1655 - mse: 4.1655\n",
      "0.5 2 15\n",
      "0.004359414 0.0002469005 0.00020622916 4.047095 4.2381864\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 102us/sample - loss: 4.0974 - mse: 4.0974\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.1033 - mse: 4.1033\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0950 - mse: 4.0950\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1158 - mse: 4.1158\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0596 - mse: 4.0596\n",
      "0.5 2 20\n",
      "0.0034631118 0.0001966661 0.00018595831 4.0488567 4.2299223\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 83us/sample - loss: 4.1210 - mse: 4.1210\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 4.0983 - mse: 4.0983\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 73us/sample - loss: 4.0274 - mse: 4.0274\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 190us/sample - loss: 4.0780 - mse: 4.0780\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 75us/sample - loss: 4.0651 - mse: 4.0651\n",
      "0.5 2 25\n",
      "0.005309922 0.00024945915 0.00019542553 4.031955 4.2413807\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0992 - mse: 4.0992\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.1172 - mse: 4.1172\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0807 - mse: 4.0807\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0822 - mse: 4.0822\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0478 - mse: 4.0478\n",
      "0.5 2 30\n",
      "0.0047294325 0.00022807295 0.00016494484 4.0343046 4.229273\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 46us/sample - loss: 4.0851 - mse: 4.0851\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0477 - mse: 4.0477\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0998 - mse: 4.0998\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0424 - mse: 4.0424\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 38us/sample - loss: 4.0960 - mse: 4.0960\n",
      "0.5 2 35\n",
      "0.004460494 0.00020973646 0.00016158892 4.031511 4.2212915\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 43us/sample - loss: 4.0417 - mse: 4.0417\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0074 - mse: 4.0074\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0724 - mse: 4.0724\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 37us/sample - loss: 4.0638 - mse: 4.0638\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0734 - mse: 4.0734\n",
      "0.5 2 40\n",
      "0.005643695 0.00023740876 0.0001692451 4.0222607 4.2253585\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 45us/sample - loss: 4.0244 - mse: 4.0244\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0528 - mse: 4.0528\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0308 - mse: 4.0308\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0535 - mse: 4.0535\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0767 - mse: 4.0767\n",
      "0.5 2 45\n",
      "0.008026611 0.00029657947 0.00018612477 4.0076413 4.2221003\n",
      "Train on 1125 samples\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 0s 44us/sample - loss: 4.0876 - mse: 4.0876\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 0s 39us/sample - loss: 4.0623 - mse: 4.0623\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 0s 42us/sample - loss: 4.0847 - mse: 4.0847\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 0s 41us/sample - loss: 4.0278 - mse: 4.0278\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 0s 40us/sample - loss: 4.0933 - mse: 4.0933\n",
      "0.5 2 50\n",
      "0.007045868 0.00023422134 0.00014131563 4.0128317 4.210597\n",
      "0.5 2 75\n",
      "0.013625439 0.00044844145 0.00021667771 3.9727318 4.200342\n",
      "0.5 2 100\n",
      "0.020949643 0.00065493805 0.0003672799 3.929003 4.2003264\n",
      "0.5 2 125\n",
      "0.0110996235 0.00044148703 0.00026313242 3.953189 4.208523\n",
      "0.5 2 150\n",
      "0.015337079 0.00062540843 0.00035300505 3.9195356 4.2038865\n",
      "0.5 2 175\n",
      "0.017876877 0.0008019963 0.00044990092 3.8976324 4.196367\n",
      "0.5 2 200\n",
      "0.022174476 0.0009908341 0.00061379664 3.8721006 4.200326\n",
      "0.5 2 225\n",
      "0.021250464 0.0010337698 0.00066123466 3.8543403 4.186513\n",
      "0.5 2 250\n",
      "0.01899631 0.0010294996 0.0006918212 3.8477573 4.195144\n",
      "0.5 2 275\n",
      "0.020724615 0.0011689072 0.0009042271 3.8305442 4.185588\n",
      "0.5 2 300\n",
      "0.020794744 0.0012876006 0.0010876318 3.8168411 4.18181\n",
      "0.5 2 325\n",
      "0.019859586 0.0012991489 0.0010920148 3.8060074 4.1844435\n",
      "0.5 2 350\n",
      "0.01601941 0.0012295729 0.0009461178 3.8270764 4.1891665\n",
      "0.5 2 375\n",
      "0.018509975 0.0014934357 0.0011367758 3.7982101 4.1867495\n",
      "0.5 2 400\n",
      "0.0185232 0.0015689908 0.0012303722 3.785937 4.172773\n",
      "0.5 2 425\n",
      "0.016847141 0.0014891747 0.0011806162 3.785717 4.171668\n",
      "0.5 2 450\n",
      "0.013054231 0.0012324197 0.0010061703 3.8025355 4.1718264\n",
      "0.5 2 475\n",
      "0.0171278 0.0015387844 0.0013095333 3.766228 4.162098\n"
     ]
    }
   ],
   "source": [
    "dataset_iter = 0\n",
    "max_epoch = 500\n",
    "with open(\"results/results_over_epoch_{}.tsv\".format(max_epoch), 'w') as results_file:\n",
    "    for add_amount, mult_amount in zip([1.0, 0.0], [0.0, 1.0]):\n",
    "        X = np.random.uniform(-1, 1, size=(1500, 25)).astype(np.float32)\n",
    "        X_query = np.random.uniform(-1, 1, size=(5000, 25)).astype(np.float32)\n",
    "        Y = (add_amount*(np.sin(X[:, 0]) + np.cos(X[:, 1])) + mult_amount*(np.sin(X[:, 2])*np.cos(X[:, 3])))\n",
    "        Y += np.random.normal(0, 2, size=(1500, ))\n",
    "        Y = Y.astype(np.float32)\n",
    "        \n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y)\n",
    "        for dropout_rate in [0.0, 0.125, 0.25, 0.375, 0.5]:\n",
    "            for fit_iter in range(3):\n",
    "                model = build_model('relu', dropout_rate, 32)\n",
    "                epoch = 0\n",
    "                while epoch < max_epoch:\n",
    "                    print(dropout_rate, fit_iter, epoch)\n",
    "                    \n",
    "                    pred = model(X_query, training=False).numpy()\n",
    "                    xgb1 = xgb(max_depth=1, n_estimators=1000)\n",
    "                    xgb2 = xgb(max_depth=2, n_estimators=1000)\n",
    "                    xgb3 = xgb(max_depth=3, n_estimators=1000)\n",
    "\n",
    "                    xgb1.fit(X_query, pred)\n",
    "                    xgb1_preds = xgb1.predict(X_query)\n",
    "                    residual1 = pred - xgb1_preds\n",
    "                    \n",
    "                    xgb2.fit(X_query, pred)\n",
    "                    xgb2_preds = xgb2.predict(X_query)\n",
    "\n",
    "                    xgb3.fit(X_query, pred)\n",
    "                    xgb3_preds = xgb3.predict(X_query)\n",
    "\n",
    "                    xgb1_var = np.var(xgb1_preds)\n",
    "                    xgb2_var = np.var(xgb1_preds - xgb2_preds)\n",
    "                    xgb3_var = np.var(xgb2_preds - xgb3_preds)\n",
    "                    \n",
    "                    train_mse = np.mean(np.square(Y_train - np.squeeze(model(X_train, training=False).numpy())))\n",
    "                    val_mse = np.mean(np.square(Y_val - np.squeeze(model(X_val, training=False).numpy())))\n",
    "                    \n",
    "                    print(xgb1_var, xgb2_var, xgb3_var, train_mse, val_mse)\n",
    "                    print('{:d}\\t{:.3f}\\t{:.3f}\\t{:d}\\t{:d}\\t{}\\t{}\\t{}\\t{}\\t{}'.format(\n",
    "                                    dataset_iter, add_amount, dropout_rate, fit_iter, epoch,\n",
    "                        xgb1_var, xgb2_var, xgb3_var, train_mse, val_mse),\n",
    "                        file=results_file, flush=True)\n",
    "                    if epoch < 50:\n",
    "                        model.fit(X_train, Y_train, epochs=5, verbose=1)\n",
    "                        epoch += 5\n",
    "                    elif epoch < max_epoch:\n",
    "                        model.fit(X_train, Y_train, epochs=25, verbose=0)\n",
    "                        epoch += 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
